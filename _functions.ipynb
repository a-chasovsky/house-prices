{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4cb6a-a83d-43f6-aa7e-7e0020fc68ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arange(arg1, arg2=None, arg3=None, arg4=None):\n",
    "    \n",
    "    '''\n",
    "    default:\n",
    "        arg1 - start\n",
    "        arg2 - stop\n",
    "        arg3 - step\n",
    "        arg4 - endpoint (True: includes, False: not includes)\n",
    "\n",
    "    variations:\n",
    "        arange(arg1) -> range(start=0, stop=arg1, step=1, endpoint=False)\n",
    "        \n",
    "        arange(arg1, arg2):\n",
    "            arange(num, num) -> (start=arg1, stop=arg2, step=1, endpoint=False)\n",
    "            arange(num, bool) -> range(start=0, stop=arg1, step=1, endpoint=arg2)\n",
    "            \n",
    "            \n",
    "        arange(arg1, arg2, arg3):\n",
    "            arange(num, num, num) -> (start=arg1, stop=arg2, step=arg3, endpoint=False)\n",
    "            arange(num, num, bool) -> range(start=arg1, stop=arg2, step=1, endpoint=arg3)\n",
    "            \n",
    "        arange(arg1, arg2, arg3, arg4) -> range(start=arg1, stop=arg2, step=arg3, endpoint=arg4)\n",
    "    '''\n",
    "\n",
    "    is_int = False\n",
    "\n",
    "    # if only one argument: arange(arg1)\n",
    "    if ((arg1 is not None) & (arg2 is None) &\n",
    "        (arg3 is None) & (arg4 is None)):\n",
    "        # equivalent (start=0, stop=arg1, step=1, endpoint=False)\n",
    "        start = 0\n",
    "        stop = arg1\n",
    "        step = 1\n",
    "        endpoint = False\n",
    "        \n",
    "        if isinstance(arg1, int):\n",
    "            is_int = True\n",
    "\n",
    "    # if two arguments: arange(arg1, arg2)\n",
    "    if ((arg1 is not None) & (arg2 is not None) &\n",
    "        (arg3 is None) & (arg4 is None)):\n",
    "        \n",
    "        # if second argument boolean: arange(number1, True)\n",
    "        if isinstance(arg2, bool):\n",
    "            # equivalent (start=0, stop=arg1, step=1, endpoint=arg2)\n",
    "            start = 0\n",
    "            stop = arg1\n",
    "            step = 1\n",
    "            endpoint = arg2\n",
    "        # if second argument not boolean: arange(number1, number2)\n",
    "        else:\n",
    "            # equivalent (start=arg1, stop=arg2, step=1, endpoint=False)\n",
    "            start = arg1\n",
    "            stop = arg2\n",
    "            step = 1\n",
    "            endpoint = False\n",
    "\n",
    "        if isinstance(arg1, int) & isinstance(arg2, int):\n",
    "            is_int = True\n",
    "\n",
    "    # if three arguments: arange(arg1, arg2, arg3)\n",
    "    if ((arg1 is not None) & (arg2 is not None) &\n",
    "        (arg3 is not None) & (arg4 is None)):\n",
    "        # if third argument boolean: arange(number1, number2, True)\n",
    "        if isinstance(arg3, bool):\n",
    "            # equivalent (start=arg1, stop=arg2, step=1, endpoint=arg3)\n",
    "            start = arg1\n",
    "            stop = arg2\n",
    "            step = 1\n",
    "            endpoint = arg3\n",
    "        # if third argument not boolean: arange(number1, number2, number3)\n",
    "        else:\n",
    "            # equivalent (start=arg1, stop=arg2, step=arg3, endpoint=False)\n",
    "            start = arg1\n",
    "            stop = arg2\n",
    "            step = arg3\n",
    "            endpoint = False\n",
    "\n",
    "        if (isinstance(arg1, int) & isinstance(arg2, int) &\n",
    "               isinstance(arg3, int)):\n",
    "            is_int = True\n",
    "\n",
    "    # if all arguments: arange(arg1, arg2, arg4, True)\n",
    "    if ((arg1 is not None) & (arg2 is not None) &\n",
    "        (arg3 is not None) & (arg4 is not None)):\n",
    "        # equivalent (start=arg1, stop=arg2, step=arg3, endpoint=arg4)\n",
    "            start = arg1\n",
    "            stop = arg2\n",
    "            step = arg3\n",
    "            endpoint = arg4\n",
    "\n",
    "    # safe form of np.arange(start, stop, step)\n",
    "    arr = step * np.arange(start/step, stop/step)\n",
    "    # if last value of arr equals to stop it concatenates to arr\n",
    "    if endpoint and arr[-1]+step==stop:\n",
    "        arr = np.concatenate([arr,[stop]])\n",
    "\n",
    "    if is_int:\n",
    "        arr = arr.astype(int)\n",
    "        \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc6ce1d-60c7-4398-9951-f5f068fb1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_rstyle(\n",
    "        y_ticks=None,\n",
    "        x_ticks=None,\n",
    "        y_slice=None,\n",
    "        x_slice=None,\n",
    "        y_lim=None,\n",
    "        x_lim=None,\n",
    "        offset_left=5,\n",
    "        offset_bottom=5,\n",
    "        width=custom_axis_linewidth,\n",
    "        margin=True,\n",
    "        color=custom_axis_color,\n",
    "        grid=False,\n",
    "        ax=None):\n",
    "    \n",
    "    '''\n",
    "    x_ticks: tuple (x_min, x_max, step)\n",
    "    y_ticks: tuple (y_min, y_max, step)\n",
    "    '''\n",
    "\n",
    "    if ax is None: ax = plt.gca()\n",
    "\n",
    "    # order of steps is important:\n",
    "        # 1 - get ticks\n",
    "        # 2 - set margins if necessary\n",
    "        # 3 - manipulations with sticks\n",
    "        # 4 - update ticks\n",
    "        # 5 - spines modification\n",
    "        # 6 - set limits\n",
    "        # 7 - tick params\n",
    "        # 8 - grid\n",
    "\n",
    "    # get ticks\n",
    "    xticks = ax.get_xticks()\n",
    "    yticks = ax.get_yticks()\n",
    "\n",
    "    if margin is not None:\n",
    "        if isinstance(margin, collections.abc.Iterable):\n",
    "            ax.margins(*margin)\n",
    "        else:\n",
    "            margin = 0.01 if margin is True else margin\n",
    "            # calculate margin coefficients coeff0 and coeff1 the way\n",
    "            # margins have to be equal\n",
    "            # 1st step: find size of figure/ax -> figisize (or ax) \n",
    "            # size should be like (ax_width, ax_height)\n",
    "            # 2d step: suggest margin_x should be equals 0.025, then\n",
    "                # ax_width * margin_x = ax_height * margin_y\n",
    "                # margin_y = (margin_x * ax_width) / ax_height\n",
    "            # so, calculated by this way values of margin_x and margin_y \n",
    "            # would make both margins equal and NOT depend on figure(or ax) size\n",
    "            ax_height, ax_width = ax.bbox.height, ax.bbox.width\n",
    "            margin_y = margin * ax_width / ax_height\n",
    "            ax.margins(x=margin, y=margin_y)\n",
    "\n",
    "    # declare xticks and yticks if necessary\n",
    "    if x_ticks is not None:\n",
    "        # if step not specified\n",
    "        if len(x_ticks) == 2:\n",
    "            x_step = xticks[1] - xticks[0]\n",
    "            x_ticks = np.append(x_ticks, x_step)\n",
    "        xticks = arange(x_ticks[0], x_ticks[1], x_ticks[2], True)\n",
    "    if y_ticks is not None:\n",
    "        # if step not specified\n",
    "        if len(y_ticks) == 2:\n",
    "            y_step = yticks[1] - yticks[0]\n",
    "            y_ticks = np.append(y_ticks, y_step)\n",
    "        yticks = arange(y_ticks[0], y_ticks[1], y_ticks[2], True)\n",
    "\n",
    "    # declare xticks and yticks with slices if necessary\n",
    "    if x_slice is not None:\n",
    "        x_slice_ = slice(*x_slice)\n",
    "        xticks = xticks[x_slice_]\n",
    "    if y_slice is not None:\n",
    "        y_slice_ = slice(*y_slice)\n",
    "        yticks = yticks[y_slice_]\n",
    "\n",
    "    # update ticks\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_yticks(yticks)\n",
    "\n",
    "    # customie spines\n",
    "    ax.spines['bottom'].set_bounds(xticks[0], xticks[-1])\n",
    "    ax.spines['bottom'].set_position(('outward', offset_bottom))\n",
    "    ax.spines['left'].set_bounds(yticks[0], yticks[-1])\n",
    "    ax.spines['left'].set_position(('outward', offset_left))\n",
    "    \n",
    "    if color:\n",
    "        ax.spines['bottom'].set_color(color)\n",
    "        ax.spines['left'].set_color(color)\n",
    "        ax.tick_params(which='both', color=color)\n",
    "\n",
    "    if width:\n",
    "        ax.spines['bottom'].set_linewidth(width)\n",
    "        ax.spines['left'].set_linewidth(width)\n",
    "        ax.tick_params(which='both', width=width)\n",
    "\n",
    "    # set limits if necessary\n",
    "    if x_lim is not None:\n",
    "        ax.set_xlim(x_lim[0], x_lim[1])\n",
    "    if y_lim is not None:\n",
    "        ax.set_ylim(y_lim[0], y_lim[1])\n",
    "    \n",
    "    # set tick params and colors\n",
    "    ax.tick_params(\n",
    "        which='both', direction='out', bottom=True, left=True)\n",
    "\n",
    "    # turn off grid\n",
    "    if not grid:\n",
    "        ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fe1c1-1ae3-40f5-9963-f9ccb10a2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_describe(data):\n",
    "    \n",
    "    df = data.copy()\n",
    "    # varibles types\n",
    "    dtypes = df.dtypes.rename('Type').to_frame()\n",
    "    # frequency\n",
    "    frequency = df.count().rename('Count').to_frame()\n",
    "    # unique values\n",
    "    unique = df.nunique().rename('Unique').to_frame()\n",
    "    # NaNs\n",
    "    nans = df.isnull().sum().rename('NaN').to_frame()\n",
    "    # NaNs fraction\n",
    "    nans_frac = df.isnull().mean().round(2)\n",
    "    nans_frac = nans_frac.rename('Percentages').to_frame()\n",
    "    # list with results\n",
    "    results_list = [dtypes, frequency, unique, nans, nans_frac]\n",
    "    # df with results\n",
    "    results = pd.concat(results_list, axis=1)\n",
    "    results['Percentages'] = (results['Percentages'] * 100).astype('int64')\n",
    "    results = results.sort_values(['NaN'], ascending=False)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13908c66-0414-493d-83b8-853a85701a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(data):\n",
    "\n",
    "    df = data.copy()\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            'condition1': 'condition_first',\n",
    "            'condition2': 'condition_second',\n",
    "            'exterior1st': 'exterior_first',\n",
    "            'exterior2nd': 'exterior_second',\n",
    "            'bsmtfintype1': 'bsmtfintype_first',\n",
    "            'bsmtfinsf1': 'bsmtfinsf_first',\n",
    "            'bsmtfintype2': 'bsmtfintype_second',\n",
    "            'bsmtfinsf2': 'bsmtfinsf_second',\n",
    "            '1stflrsf': 'first_flrsf',\n",
    "            '2ndflrsf': 'second_flrsf',\n",
    "            '3ssnporch': 'three_ssnporch'\n",
    "            }\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76819eee-4922-4d18-838d-de6f189a0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_outliers_create(df, quant_features, scale=1.5, boundaries=False):\n",
    "    \n",
    "    index = ['Count', \n",
    "             'Outliers', 'Lower Outliers', 'Upper Outliers',\n",
    "             'Lower Fence', 'Upper Fence', \n",
    "             'Q25', 'Q75', 'IQR', 'Scale']\n",
    "    \n",
    "    boundaries_dict = {}\n",
    "    # словарь, в котором ключи - признаки,\n",
    "    # а значения - верхние и нижние выбросы, а также q25, q75, iqr, lower, upper, scale\n",
    "    outliers_dict = {}\n",
    "    \n",
    "    for feature in quant_features:\n",
    "        \n",
    "        q25, q75 = np.nanpercentile(df[feature], [25, 75])\n",
    "        iqr = q75 - q25\n",
    "        lower_boundary = q25 - (scale * iqr)\n",
    "        upper_boundary = q75 + (scale * iqr)\n",
    "        \n",
    "        lower_ouliers = len(df[df[feature] < lower_boundary])\n",
    "        upper_outliers = len(df[df[feature] > upper_boundary])\n",
    "        outliers = lower_ouliers + upper_outliers\n",
    "\n",
    "        dict_data = [\n",
    "            df[feature].count(), # общее число элементов признака i\n",
    "            outliers, lower_ouliers, upper_outliers,\n",
    "            lower_boundary, upper_boundary,\n",
    "            q25, q75, iqr,  scale\n",
    "        ]\n",
    "        \n",
    "        outliers_dict['{0}'.format(feature)] = [round(i,2) for i in dict_data]\n",
    "        \n",
    "        boundaries_dict[feature] = [lower_boundary, upper_boundary]\n",
    "    \n",
    "    outliers_df = pd.DataFrame(outliers_dict, index=index)\n",
    "    \n",
    "    if boundaries:\n",
    "        return outliers_df, boundaries_dict\n",
    "    else:\n",
    "        return outliers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a6008-73fa-4456-8af7-5796431ffa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_outliers(df_outliers):\n",
    "    \n",
    "    plt.figure(figsize=(6,3))\n",
    "    ax = sns.barplot(\n",
    "        x=df_outliers.columns,\n",
    "        y=df_outliers.loc['Outliers'] / df_outliers.loc['Count'] * 100,\n",
    "        width=0.6,\n",
    "        color=palette[0]\n",
    "    )\n",
    "    ax.tick_params(axis='both', which='major', labelsize=9)\n",
    "    ax.set_ylabel('Persentages', fontsize=10, weight='bold')\n",
    "    ax.yaxis.set_label_coords(-0.11, 0.46)\n",
    "    plt.title('Outliers', fontsize=10, weight='bold')\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b975c2ab-9e7e-4bb9-aeaf-d0ae12e4796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_na(data, features_list):\n",
    "\n",
    "    df = data.copy()\n",
    "    for feature in features_list:\n",
    "        df[feature] = df[feature].fillna('NA')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea52fb9-051e-434d-b615-35dc0e3cf945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview_transformation(\n",
    "        data, features_na, imputer_categorical,\n",
    "        imputer_quantitative, variable_target, log_target=False):        \n",
    "\n",
    "    df = data.copy()\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    # rename predictors for linear models (statsmodels)\n",
    "    df = rename_columns(df)\n",
    "    # fill NaNs by 'NA' for categorical variables\n",
    "    df[features_na] = df[features_na].fillna('NA')\n",
    "    # imput NaNs for other categorical variables\n",
    "    df = imputer_categorical.transform(df)\n",
    "\n",
    "    garage_fill = df.loc[df['garageyrblt'].isna(), 'yearbuilt']\n",
    "    loc = df['garageyrblt'].isna(), 'garageyrblt'\n",
    "    df.loc[loc] = df.loc[loc].fillna(garage_fill)\n",
    "    # median imput for quantitative variables\n",
    "    df = imputer_quantitative.transform(df)\n",
    "\n",
    "    if log_target:\n",
    "        # log target variable\n",
    "        df[variable_target] = np.log(df[variable_target])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd19d1-2881-49e2-a15f-267cf8197b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(\n",
    "        features, importance, labels=False,\n",
    "        width=6, height=15, coeff_xaxis=-1.5, \n",
    "        top=None, lower_limit=None):\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importance\n",
    "    })\n",
    "    feature_importance = (feature_importance\n",
    "                          .sort_values('Importance', ascending=False)\n",
    "                          .reset_index(drop=True))\n",
    "    if lower_limit:\n",
    "        loc_limit_rows = (feature_importance['Importance'] >= lower_limit)\n",
    "        feature_importance = (feature_importance\n",
    "                              .loc[loc_limit_rows, :])\n",
    "    if top: \n",
    "        loc_limit_rows = slice(0, top-1)\n",
    "        feature_importance = (feature_importance\n",
    "                              .loc[loc_limit_rows, :])\n",
    "    \n",
    "    x = feature_importance['Importance']\n",
    "    y = feature_importance['Feature']\n",
    "    # reverse y ticks\n",
    "    x = x.iloc[::-1]\n",
    "    y = y.iloc[::-1]\n",
    "    # k = (x.max() - x.min())/len(x) * 0.75\n",
    "    # figure\n",
    "    f, ax = plt.subplots(figsize=(width, height))\n",
    "    xlim = feature_importance['Importance'].max() * 1.1\n",
    "    ylim = ax.get_ylim()\n",
    "    # f.suptitle('Feature Importance', fontsize=11, y=0.01*coeff_title)\n",
    "    plt.hlines(\n",
    "        xmin=0, xmax=x, y=y, linewidth=2,\n",
    "        color=palette[-2], alpha=0.55)\n",
    "    plt.plot(\n",
    "        x, y, 'o', markersize=3.5, color=palette[-4], alpha=1)\n",
    "    if labels:\n",
    "        for x, y in zip(x, y):\n",
    "            plt.text(\n",
    "                x=x*1.2, y=y, s='{:.3f}'.format(x), size=8,\n",
    "                horizontalalignment='center', verticalalignment='bottom',\n",
    "                bbox={\n",
    "                    'boxstyle': 'round',\n",
    "                    'facecolor': 'none',\n",
    "                    'edgecolor': '0.75'\n",
    "                }\n",
    "            )\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlim(0, xlim)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.spines['top'].set_position(('outward', coeff_xaxis*height))\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['left'].set_bounds((-0.5, len(feature_importance)-0.5))\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    plt.grid(None)\n",
    "    yticks = np.arange(len(features)-1, -1, -1)\n",
    "    yticklabels = [str.upper(i) for i in features]\n",
    "    plt.yticks(ticks=yticks, labels=yticklabels, fontsize=9)\n",
    "    plt.grid(None)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9020e-fdae-46cc-9c27-0abc25fbc221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_features(data, features_log):\n",
    "    df = data.copy()\n",
    "    for feature in features_log:\n",
    "        # const = abs(np.min(df[feature])) + 1\n",
    "        const = 1\n",
    "        df[feature] = np.log(df[feature] + const)\n",
    "        df = df.rename(columns={feature: 'lg_'+feature})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3279930c-62e9-40a8-933a-2b90486123ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_feature_selection(data, features_log, target, factors=True):\n",
    "\n",
    "    df = data.copy()\n",
    "    df['flrsfmean'] = ((df['first_flrsf']\n",
    "                       + 0.7*df['second_flrsf']) / 2)\n",
    "    df['totrms'] = (df['totrmsabvgrd']\n",
    "                   - df['bedroomabvgr']\n",
    "                   - df['kitchenabvgr'])\n",
    "    df['bedroomsze'] = (df['bedroomabvgr'] / df['grlivarea'])\n",
    "    df['kitchensze'] = (df['kitchenabvgr'] / df['grlivarea'])\n",
    "    # 'bedroomfracrms' feature\n",
    "    df['bedroomfracrms'] = (df['bedroomabvgr'] / df['totrms'])\n",
    "    # max value of 'bedroomfracrms' except inf\n",
    "    loc_value = (~np.isinf(df['bedroomfracrms']), 'bedroomfracrms')\n",
    "    value = df.loc[loc_value].max()\n",
    "    # fill inf values with max value\n",
    "    loc_r = np.isinf(df['bedroomfracrms'])\n",
    "    df.loc[loc_r, 'bedroomfracrms'] = value\n",
    "    # 'kitchenfracrms' feature\n",
    "    df['kitchenfracrms'] = (df['kitchenabvgr'] / df['totrms'])\n",
    "    # max value of 'kitchenfracrms' except inf\n",
    "    loc_value = (~np.isinf(df['kitchenfracrms']), 'kitchenfracrms')\n",
    "    value = df.loc[loc_value].max()\n",
    "    # fill inf values with max value\n",
    "    loc_r = np.isinf(df['kitchenfracrms'])\n",
    "    df.loc[loc_r, 'kitchenfracrms'] = value\n",
    "    # fill NaN values by 0\n",
    "    df['kitchenfracrms'] = df['kitchenfracrms'].fillna(0)\n",
    "    # 'bathsfracbedr' feature\n",
    "    df['bathsfracbedr'] = (df['fullbath'] / df['bedroomabvgr'])\n",
    "    # max value of 'bathsfracbedr' except inf\n",
    "    loc_value = (~np.isinf(df['bathsfracbedr']), 'bathsfracbedr')\n",
    "    value = df.loc[loc_value].max()\n",
    "    # fill inf values with max value\n",
    "    loc_r = np.isinf(df['bathsfracbedr'])\n",
    "    df.loc[loc_r, 'bathsfracbedr'] = value\n",
    "    # fill NaN values by 0\n",
    "    df['bathsfracbedr'] = df['bathsfracbedr'].fillna(0)\n",
    "\n",
    "    if factors:\n",
    "        features_to_factor = [\n",
    "            'yearremodadd', 'masvnrarea', 'bsmtfinsf_first', 'bsmtfinsf_second', \n",
    "            'totalbsmtsf', 'bsmtunfsf', 'lowqualfinsf', 'second_flrsf', 'garagearea',\n",
    "            'wooddecksf', 'openporchsf', 'enclosedporch', 'three_ssnporch',\n",
    "            'screenporch', 'poolarea', 'miscval'\n",
    "        ]\n",
    "        for feature in features_to_factor:\n",
    "            new_feature_name = feature + '_exst'\n",
    "            df[new_feature_name] = (df[feature] != 0).astype(int)\n",
    "        \n",
    "    df['yearremodadd_exst'] = (df['yearremodadd']!=df['yearbuilt']).astype(int)\n",
    "    cond = (df['yearremodadd_exst']==1)\n",
    "    outcome1 = (df['yrsold'] - df['yearremodadd'])\n",
    "    outcome0 = (df['yrsold'] - df['yearbuilt'])\n",
    "    df['modage'] = np.where(cond, outcome1, outcome0)\n",
    "    # df = df.drop('yearremodadd_exst', axis=1)\n",
    "    \n",
    "    df['houseage'] = df['yrsold'] - df['yearbuilt']\n",
    "    df['garageage'] = df['yrsold'] - df['garageyrblt']\n",
    "    \n",
    "    features_log = [\n",
    "        'masvnrarea', 'bsmtfinsf_first', 'bsmtfinsf_second', 'bsmtunfsf',\n",
    "        'totalbsmtsf', 'first_flrsf', 'second_flrsf', 'lowqualfinsf',\n",
    "        'grlivarea', 'garageyrblt', 'garagearea', 'wooddecksf',\n",
    "        'openporchsf', 'enclosedporch', 'three_ssnporch', 'screenporch',\n",
    "        'poolarea', 'miscval', 'houseage', 'lotfrontage', 'lotarea'\n",
    "    ]\n",
    "    \n",
    "    df = log_features(df, features_log)\n",
    "\n",
    "    for feature in features_log:\n",
    "        df = df.rename(columns={feature: 'lg_'+feature})\n",
    "        # rename elements in features list: add 'lg_'\n",
    "        # dct = {feature: 'lg_'+feature}\n",
    "        # features = [dct.get(n, n) for n in features]\n",
    "        # numeric = [dct.get(n, n) for n in numeric]\n",
    "\n",
    "    col = df.pop(target)\n",
    "    df.insert(len(df.columns), target, col)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80efbca-2ade-431a-ac7d-1292b773bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_matrix(\n",
    "        data, target, num_features=None, vars_color='0.3', vars_weight='medium',\n",
    "        width=0.7, height=0.4, annot=5, labelsize=9, full=True,\n",
    "        abs_results=True, plot=True, linecolor='light', df=False, df_limit=None):\n",
    "    \n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    if num_features: \n",
    "        idx = num_features + 1\n",
    "        width = num_features * width\n",
    "        height = num_features * height\n",
    "    else:\n",
    "        idx = 0\n",
    "        width = len(data_copy) * width\n",
    "        height = len(data_copy) * height\n",
    "\n",
    "    if abs_results:\n",
    "        data = data.sort_values(target, ascending=False, key=abs)[:idx]\n",
    "    else:\n",
    "        data = data.sort_values(target, ascending=False)[:idx]\n",
    "        \n",
    "    cols = data.index\n",
    "    data = data[cols]\n",
    "    data = data.iloc[1:]\n",
    "\n",
    "    if plot:\n",
    "        f = plt.figure(figsize=(width, height))\n",
    "        cmap = corr_matrix\n",
    "        if linecolor == 'dark':\n",
    "            linecolor = '#282828'\n",
    "        else:\n",
    "            linecolor = '#FFFFFF'\n",
    "        if full:\n",
    "            data = np.round(data, 2)\n",
    "            ax = sns.heatmap(\n",
    "                data=data, cmap=cmap, annot=True, vmax=1, vmin=-1,\n",
    "                center=0, square=False, linewidths=0.5, linecolor=linecolor,\n",
    "                annot_kws={'size': annot}, cbar=False\n",
    "            )\n",
    "        else:\n",
    "            mask = np.triu(data)\n",
    "            data = np.round(data, 2)\n",
    "            ax = sns.heatmap(\n",
    "                data=data, cmap=cmap, annot=True, vmax=1, vmin=-1,\n",
    "                center=0, square=False, linewidths=0.5, linecolor=linecolor,\n",
    "                mask=mask, annot_kws={'size': annot}, cbar=False\n",
    "            )\n",
    "        ax.xaxis.tick_top()\n",
    "        xtickslabels = data.columns.tolist()\n",
    "        xtickslabels = [str.upper(i) for i in xtickslabels]\n",
    "        xtickslabels = xtickslabels[::-1]\n",
    "        xticks = np.arange(len(xtickslabels)-1, -1, -1)\n",
    "        xticks = [(i+0.5) for i in xticks]\n",
    "        plt.xticks(\n",
    "            ticks=xticks, labels=xtickslabels, fontsize=labelsize,\n",
    "            weight=vars_weight, rotation=90)\n",
    "        plt.tick_params(\n",
    "            axis='x', labelcolor=vars_color, bottom=False,\n",
    "            top=True, labelbottom=False, pad=7)\n",
    "        ytickslabels = data.index.tolist()\n",
    "        ytickslabels = [str.upper(i) for i in ytickslabels]\n",
    "        ytickslabels = ytickslabels[::-1]\n",
    "        yticks = np.arange(len(ytickslabels)-1, -1, -1)\n",
    "        yticks = [(i+0.5) for i in yticks]\n",
    "        plt.yticks(\n",
    "            ticks=yticks, labels=ytickslabels, fontsize=labelsize,\n",
    "            weight=vars_weight)\n",
    "        plt.tick_params(axis='y', labelcolor=vars_color, pad=7)\n",
    "        plt.show()\n",
    "\n",
    "    if df:\n",
    "        data_copy['sort'] = abs(data_copy[target])\n",
    "        data_copy = data_copy.sort_values('sort', ascending=False)\n",
    "        data_copy = data_copy.drop('sort', axis=1)\n",
    "\n",
    "        if df_limit:\n",
    "            last_idx = df_limit + 1\n",
    "        else:\n",
    "            last_idx = len(data_copy)\n",
    "           \n",
    "        data_copy = data_copy[target][1:last_idx].to_frame()\n",
    "        \n",
    "        return f, data_copy\n",
    "    else:\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632754f7-e606-4834-b7e5-472ee4501a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_categorical_create(x, y, variables):\n",
    "    \n",
    "    arr = np.array([])\n",
    "\n",
    "    for variable in variables:\n",
    "        x_lr = pd.get_dummies(x[variable], dtype='float')\n",
    "        lr = sm.OLS(y, x_lr).fit()\n",
    "        arr = np.append(arr, np.round(lr.rsquared, 3))\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842dd2af-8e81-4f5c-ba42-635cb9f4ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_inline(\n",
    "        data, features, target, ci=95, kind='line',\n",
    "        order=False, rotation=False, **kwargs):\n",
    "\n",
    "    k=1\n",
    "    ncols = len(features)\n",
    "    fig, axes = plt.subplots(1, ncols, figsize=(5*ncols,3))\n",
    "    \n",
    "    for feature in features:\n",
    "        plt.subplot(1, ncols, k)\n",
    "        if kind == 'line':\n",
    "            sns.regplot(\n",
    "                data=data,\n",
    "                x=feature,\n",
    "                y=target,\n",
    "                marker='.',\n",
    "                scatter_kws={\n",
    "                    'alpha': 0.75\n",
    "                },\n",
    "                line_kws={\n",
    "                    'color': palette[-2],\n",
    "                    'alpha':0.5\n",
    "                },\n",
    "                **kwargs\n",
    "            ) \n",
    "        else:\n",
    "            if order:\n",
    "                order_ = (data[[feature, target]]\n",
    "                          .groupby(feature)\n",
    "                          .mean()\n",
    "                          .sort_values(target, ascending=False)\n",
    "                          .index\n",
    "                          .tolist())\n",
    "            else:\n",
    "                order_ = None\n",
    "            sns.pointplot(\n",
    "                data=data,\n",
    "                x=feature,\n",
    "                y=target,\n",
    "                order=order_,\n",
    "                errwidth=1.5,\n",
    "                scale=0.65,\n",
    "                capsize=0.05,\n",
    "                join=False,\n",
    "                **kwargs\n",
    "            )\n",
    "        plt.ylabel(None)\n",
    "        if rotation:\n",
    "            plt.xticks(rotation=rotation)\n",
    "        k +=1\n",
    "        \n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec8541-2ca1-4067-a011-bac61ec69837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_var(df, var_list, except_zeros=True):\n",
    "\n",
    "    for var in var_list:\n",
    "        df.loc[df[var]>0, var] = np.log(df[df[var]>0][var])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b7652a-b8d7-4f94-bbfe-a4f0a4705c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_exist_feature_create(df, var_list):\n",
    "\n",
    "    for var in var_list:\n",
    "        df[var+'_exst'] = df[var]>0\n",
    "        df[var+'_exst'] = df[var+'_exst'].astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f60cc-3115-497f-be1e-64e1104e416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_numeric(data, variable, target, hue=None):\n",
    "\n",
    "    f = plt.figure(figsize=(9,3.5))\n",
    "    f.suptitle(\n",
    "        variable.title(), fontsize=11,\n",
    "        weight='bold', color='0.45')\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    ax1 = sns.histplot(\n",
    "        data=data,\n",
    "        x=variable,\n",
    "        hue=hue,\n",
    "        alpha=0.95\n",
    "    )\n",
    "    plt.subplot(1, 2, 2)\n",
    "    ax2 = sns.regplot(\n",
    "        data=data,\n",
    "        x=variable,\n",
    "        y=target,\n",
    "        marker='.',\n",
    "        scatter_kws={\n",
    "            'alpha': 0.75\n",
    "        },\n",
    "        line_kws={\n",
    "            'color': palette[-2],\n",
    "            'alpha': 0.75\n",
    "        }\n",
    "    )\n",
    "    ax1.set(xlabel=None)\n",
    "    ax2.set(xlabel=None)\n",
    "    ax2.set_ylabel(ax2.get_ylabel().capitalize())\n",
    "    ax1.set_ylabel(ax1.get_ylabel().capitalize())\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    plt.show()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6411a10-038f-420d-a96f-23b3e5dc3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_categorical(\n",
    "        data, variable, target, ci=95,\n",
    "        rotation=None, order=None):\n",
    "    \n",
    "    # nunique = data[variable].nunique()\n",
    "    f = plt.figure(figsize=(9,3.5))\n",
    "    f.suptitle(\n",
    "        variable.title(), fontsize=11,\n",
    "        weight='bold', color='0.45')\n",
    "\n",
    "    if order:\n",
    "        order = order\n",
    "        \n",
    "    plt.subplot(1, 2, 1)\n",
    "    ax1 = sns.countplot(\n",
    "        data=data,\n",
    "        x=variable,\n",
    "        order=order,\n",
    "        color=palette[0],\n",
    "        saturation=0.75,\n",
    "        width=0.5\n",
    "    )\n",
    "    plt.xticks(rotation=rotation)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    ax2 = sns.pointplot(\n",
    "        data=data,\n",
    "        x=variable,\n",
    "        y=target,\n",
    "        order=order,\n",
    "        errorbar=('ci', ci),\n",
    "        errwidth=1.5,\n",
    "        scale=0.65,\n",
    "        capsize=0.05,\n",
    "        join=False,\n",
    "        color=palette[0]\n",
    "    )\n",
    "    ax1.set(xlabel=None)\n",
    "    ax2.set(xlabel=None)\n",
    "    ax1.set_ylabel(ax1.get_ylabel().capitalize())\n",
    "    ax2.set_ylabel(ax2.get_ylabel().capitalize())\n",
    "    plt.xticks(rotation=rotation)\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    plt.show()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834083e-9d6f-4574-9e10-43ff0eb1ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_columns_match(data):\n",
    "\n",
    "    df = data.copy()\n",
    "    df['is_equal'] = df.eq(df.iloc[:, 0], axis=0).all(1).astype(int)\n",
    "    equal_sum = df['is_equal'].sum()\n",
    "\n",
    "    if equal_sum == len(df):\n",
    "        print('All values matched')\n",
    "        return None\n",
    "    else:\n",
    "        loc = df['is_equal'] == 0, df.columns != 'is_equal'\n",
    "        result = df.loc[loc].copy()\n",
    "        return result      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53f126-12db-47d0-9f2e-3fade9fddecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vif_preprop(data, drop_first=False):\n",
    "    \n",
    "    df = data.copy()\n",
    "    df = pd.get_dummies(df, drop_first=drop_first, dtype=int)\n",
    "    sc = MinMaxScaler(feature_range=(0,1))\n",
    "    \n",
    "    df_minmax = sc.fit_transform(df)\n",
    "    df_minmax = pd.DataFrame(\n",
    "        data=df_minmax,\n",
    "        index=df.index,\n",
    "        columns=df.columns\n",
    "    )\n",
    "    return df_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b02d1-b515-47df-a110-26da41c9e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vif(data):\n",
    "\n",
    "    exogs = data.columns\n",
    "    vif_dict, tolerance_dict = {}, {}\n",
    "\n",
    "    for exog in exogs:\n",
    "        not_exog = [i for i in exogs if i != exog]\n",
    "        X, y = data[not_exog], data[exog]\n",
    "\n",
    "        r_squared = LinearRegression().fit(X, y).score(X, y)\n",
    "\n",
    "        vif = 1/(1 - r_squared)\n",
    "        vif_dict[exog] = vif\n",
    "\n",
    "        tolerance = 1 - r_squared\n",
    "        tolerance_dict[exog] = tolerance\n",
    "\n",
    "    df_vif = pd.DataFrame({\n",
    "        'VIF': vif_dict,\n",
    "        'Tolerance': tolerance_dict\n",
    "    })\n",
    "    df_vif = df_vif.sort_values('VIF', ascending=0)\n",
    "    \n",
    "    return df_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254641e7-be3e-4138-b971-e566fb78582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_group(features):\n",
    "    df = train[features + [target]].copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72733233-bbb7-41fe-a848-aca6bffae196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_w_target(data, target):\n",
    "    df = (data\n",
    "          .corr()[target]\n",
    "          .sort_values(ascending=False, key=abs)[1:]\n",
    "          .to_frame())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62339db8-da4b-416a-8624-6a8e2c8603cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_correct_after_oh(data1, data2):\n",
    "\n",
    "    df1 = data1.copy()\n",
    "    df2 = data2.copy()\n",
    "    idx1 = df1.index\n",
    "    idx2 = df2.index\n",
    "    \n",
    "    cols = list(set(list(df1.columns) + list(df2.columns)))\n",
    "    df_nans1 = pd.DataFrame(columns=cols, index=df1.index)\n",
    "    df_nans2 = pd.DataFrame(columns=cols, index=df2.index)\n",
    "    \n",
    "    df1 = df1.merge(df_nans1, how='left', sort=False)\n",
    "    df2 = df2.merge(df_nans1, how='left', sort=False)\n",
    "\n",
    "    df1.index = idx1\n",
    "    df2.index = idx2\n",
    "    df2.columns = df1.columns\n",
    "\n",
    "    df1 = df1.fillna(0)\n",
    "    df2 = df2.fillna(0)\n",
    "\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33bc2e-746a-4418-b2bd-83b3294e618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_new_features(data, features_list):\n",
    "    \n",
    "    df = data.copy()\n",
    "    y = df[target]\n",
    "    results_dct = {\n",
    "        'features': [],\n",
    "        'mrse': [],\n",
    "        'vif_max_value': []\n",
    "    }\n",
    "    for features in features_list:\n",
    "        if len(features) > 1:\n",
    "            x = df[features]\n",
    "            x = StandardScaler().fit_transform(x)\n",
    "        else:\n",
    "            x = df[features[0]].values.reshape(-1, 1)\n",
    "            x = StandardScaler().fit_transform(x)\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(x, y)\n",
    "        mrse = mean_squared_error(y, lr.predict(x), squared=False)\n",
    "        results_dct['features'].append(features)\n",
    "        results_dct['mrse'].append(mrse)\n",
    "        if len(features) > 1:\n",
    "            vif_value = vif(pd.DataFrame(x)).iloc[0,0]\n",
    "            results_dct['vif_max_value'].append(vif_value)\n",
    "        else:\n",
    "            results_dct['vif_max_value'].append(0)\n",
    "\n",
    "    results = pd.DataFrame(results_dct)\n",
    "    results = results.sort_values('mrse')\n",
    "    results['features'] = results['features'].str.join(', ')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93663d37-5b61-4456-b787-ec48c7c6aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_results_partial(cv_results, slices=None, n_folds=5):\n",
    "    \n",
    "    results = pd.DataFrame(columns=[\n",
    "        'rmse', 'params', 'std', 'std_err',\n",
    "        'split0', 'split1', 'split2', 'split3', 'split4'\n",
    "    ])\n",
    "    if slices:\n",
    "        slice_x=slices[0]\n",
    "        slice_y=slices[1]\n",
    "        range_x = 0\n",
    "        range_y = slice_y - slice_x\n",
    "        \n",
    "    else:\n",
    "        slice_x = 0\n",
    "        slice_y = len(cv_results['mean_test_score'])\n",
    "        range_x = 0\n",
    "        range_y = len(cv_results['mean_test_score'])\n",
    "\n",
    "    scorescv = cv_results['mean_test_score'][slice_x:slice_y]\n",
    "    paramscv = cv_results['params'][slice_x:slice_y]\n",
    "    stdcv = cv_results[\"std_test_score\"][slice_x:slice_y]\n",
    "    \n",
    "    for idx in np.arange(range_x, range_y, 1):\n",
    "        score = abs(scorescv[idx])\n",
    "        dct = paramscv[idx]\n",
    "        alpha = dct['alpha']\n",
    "        alpha = str(np.round(alpha, 4))\n",
    "        l1_ratio = dct['l1_ratio']\n",
    "        l1_ratio = str(np.round(l1_ratio, 1))\n",
    "        std = stdcv[idx]\n",
    "        std_err = std / np.sqrt(n_folds)\n",
    "        params = alpha + '/' + l1_ratio\n",
    "        new_row = [score, params, std, std_err]\n",
    "        \n",
    "        for split in np.arange(0, n_folds):\n",
    "            split_name = 'split' + str(split) + '_test_score'\n",
    "            split_values = abs(cv_results[split_name][slice_x:slice_y][idx])\n",
    "            new_row.append(split_values)\n",
    "            \n",
    "        results.loc[len(results), results.columns] = new_row\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc643ba-77e3-411c-bdc2-91389bb1c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_results_params_transform(cv_results_df, param_cols, round_list):\n",
    "    \n",
    "    df = cv_results_df.copy()\n",
    "    zipp = zip(param_cols, round_list)\n",
    "    \n",
    "    for col, scale in zipp:\n",
    "        df[col] = df[col].astype(float)\n",
    "        df[col] = df[col].round(scale)\n",
    "\n",
    "    df['params_new'] = ''\n",
    "    for col in param_cols:\n",
    "        add_param = df[col].astype(str)\n",
    "        df['params_new'] = df['params_new'] + '/' + add_param\n",
    "\n",
    "    df['params_new'] = df['params_new'].apply(lambda x: x.lstrip('/'))\n",
    "    idx = df.columns.get_loc('params')\n",
    "    df.insert(loc=idx, column='parameters', value=df['params_new'])\n",
    "    df = df.drop('params_new', axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6f7f0-9d14-475b-8702-9ee31815e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_model_data_formula(data, target, predictors=None):\n",
    "    \n",
    "    if predictors is None:\n",
    "        # put target to the end of data\n",
    "        cols = data.columns.tolist()\n",
    "        cols.append(cols.pop(cols.index(target)))\n",
    "        df = data[cols].copy()\n",
    "        predictors = ' + '.join(df.columns[:-1])\n",
    "    else:\n",
    "        df = data.copy()\n",
    "        predictors = ' + '.join(predictors)\n",
    "\n",
    "    formula = target + ' ~ ' + predictors\n",
    "    \n",
    "    return df, formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25fe3d-2bd7-47cc-8e9a-9cab74fc95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_regressions(\n",
    "        data, target, model1, model2, model_names,\n",
    "        sample_frac=0.3, n_folds=1000):\n",
    "    \n",
    "    # put target column to the end of columns\n",
    "    cols = data.columns.tolist()\n",
    "    cols.append(cols.pop(cols.index(target)))\n",
    "    df = data[cols].copy()\n",
    "    features = df.columns[:-1]\n",
    "    dct = {i:[] for i in model_names}\n",
    "    \n",
    "    range = np.arange(0, n_folds, 1)\n",
    "    for i in range:\n",
    "        smpl = df.sample(frac=sample_frac, replace=True)\n",
    "        x = smpl.iloc[:, :-1]\n",
    "        y = smpl.iloc[:, -1]\n",
    "        \n",
    "        y_pred1 = model1.predict(x)\n",
    "        rmse1 = mean_squared_error(y, y_pred1, squared=False)\n",
    "        y_pred2 = model2.predict(x)\n",
    "        rmse2 = mean_squared_error(y, y_pred2, squared=False)\n",
    "        \n",
    "        dct[model_names[0]].append(rmse1)\n",
    "        dct[model_names[1]].append(rmse2)\n",
    "        \n",
    "    res = pd.DataFrame(dct)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17f964-7d4f-46ce-a441-bb5193c8855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breusch_pagan_lagrange_test(model):\n",
    "    name = ['Lagrange multiplier statistic', 'p_value', 'f_value', 'f_p_value']\n",
    "    statistic = sm.stats.het_breuschpagan(model.resid, model.model.exog)\n",
    "    dct = dict(zip(name, statistic))\n",
    "    if ((dct['p_value'] < 0.05) |\n",
    "        (dct['f_p_value'] < 0.05)):\n",
    "        print('The test assumes heteroscedasticity')\n",
    "    else:\n",
    "        print('The test assumes homoscedasticity')\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39ba1c-a899-4aa8-8457-7dc796cfb644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def omnibus_test(model):\n",
    "    name = ['Chi^2', 'Two-tail probability']\n",
    "    statistic = sm.stats.omni_normtest(model.resid)\n",
    "    dct = dict(zip(name, statistic))\n",
    "    if dct['Two-tail probability'] < 0.05:\n",
    "        print('The test assumes, that residuals distribution not gaussian')\n",
    "    else:\n",
    "        print('The test assumes, that residuals distribution is gaussian')\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4701090-ea3f-4687-923b-e2d78dd392a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goldfeld_quandt_test(model):\n",
    "    name = [\"F statistic\", \"p_value\"]\n",
    "    statistic = sms.het_goldfeldquandt(model.resid, model.model.exog)\n",
    "    dct = dict(zip(name, statistic))\n",
    "    if dct['p_value'] < 0.05:\n",
    "        print('The test assumes heteroscedasticity')\n",
    "    else:\n",
    "        print('The test assumes homoscedasticity')\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca907f72-962a-4952-a73f-b798963fb13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jarque_bera_test(model):\n",
    "    name = [\"Jarque-Bera\", \"Chi^2 Two-tail probability\", \"Skew\", \"Kurtosis\"]\n",
    "    statistic = sms.jarque_bera(model.resid)\n",
    "    dct = dict(zip(name, statistic))\n",
    "    if dct['Chi^2 Two-tail probability'] < 0.05:\n",
    "        print('The test assumes, that skewness and kurtosis'\n",
    "              ' not matching a normal distribution')\n",
    "    else:\n",
    "        print('The test assumes, that skewness and kurtosis'\n",
    "              ' matching a normal distribution')\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a68c1-c465-40b3-878a-98addf454bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ramsey_reset(model, alpha=0.05):\n",
    "\n",
    "    tests_names = 'Ramsey’s RESET'\n",
    "    # category_names = 'Model'\n",
    "    pvalue = []\n",
    "    # result = []\n",
    "    condition = []\n",
    "    \n",
    "    reset_test = reset_ramsey(model, degree=5)\n",
    "    pvalue_reset = reset_test.pvalue\n",
    "    if pvalue_reset < alpha:\n",
    "        condition.append('Non-linear effects')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('No non-linear effects')\n",
    "        # result.append('Passed')\n",
    "    pvalue_reset = np.round(pvalue_reset, 2)\n",
    "    pvalue.append(pvalue_reset)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        # 'Category': category_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "        # 'Result': result\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d410598c-1b17-4399-a626-d6387ef339bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lr_multicollinearity(model):\n",
    "\n",
    "    tests_names = 'Condition Number (s)'\n",
    "    # category_names = 'Predictors'\n",
    "    # result = []\n",
    "    condition = []\n",
    "    \n",
    "    # condition number\n",
    "    mult = np.linalg.cond(model.model.exog)\n",
    "    if mult < 15:\n",
    "        condition.append('No multicollinearity')\n",
    "        # result.append('Passed')\n",
    "    else:\n",
    "        condition.append('Multicollinearity')\n",
    "        # result.append('Not passed')\n",
    "        \n",
    "    pvalue = np.round(mult, 4)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        # 'Category': category_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "        # 'Result': result\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ffa85-8951-4617-b9e5-5b714d8e09ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lr_cooks_distance(model):\n",
    "\n",
    "    tests_names = \"Cook's Distance (s)\"\n",
    "    # category_names = 'Outliers'\n",
    "    condition = []\n",
    "    # result = []\n",
    "    # cook's distance\n",
    "    cooksd = model.get_influence().cooks_distance[0]\n",
    "    cooksd_border = 4/len(cooksd)\n",
    "    outliers_num = (cooksd > cooksd_border).sum()\n",
    "    if outliers_num > 0:\n",
    "        condition.append('Outliers detected')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('No outliers')\n",
    "        # result.append('Passed')\n",
    "        \n",
    "    pvalue = np.round(outliers_num, 4)\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        # 'Category': category_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "        # 'Result': result\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089070d6-40a2-4672-b652-9c1a2b4e1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normality(data, alpha=0.05):\n",
    "    \n",
    "    # category_names = []\n",
    "    tests_names = []\n",
    "    pvalue = []\n",
    "    condition = []\n",
    "    # result = []\n",
    "        \n",
    "    # Kolmogorov-Smirnov\n",
    "    ks = stats.kstest(data, 'norm')\n",
    "    pvalue_ks = ks.pvalue\n",
    "    # category_names.append('Residuals')\n",
    "    tests_names.append('Kolmogorov-Smirnov')\n",
    "    pvalue.append(pvalue_ks)\n",
    "    if pvalue_ks < alpha:\n",
    "        condition.append('Not normal')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "        # result.append('Passed')\n",
    "\n",
    "    # Anderson-Darling\n",
    "    and_dar = stats.anderson(data, dist='norm')\n",
    "    and_dar_sign = and_dar.critical_values[2]\n",
    "    and_dar_statistic = and_dar.statistic\n",
    "    # category_names.append('Residuals')\n",
    "    tests_names.append('Anderson-Darling (s)')\n",
    "    pvalue.append(and_dar_statistic)\n",
    "    if and_dar_statistic > and_dar_sign:\n",
    "        condition.append('Not normal')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "        # result.append('Passed')\n",
    "\n",
    "    # Shapiro-Wilk\n",
    "    pvalue_sw = stats.shapiro(data).pvalue\n",
    "    # category_names.append('Residuals')\n",
    "    tests_names.append('Shapiro-Wilk')\n",
    "    pvalue.append(pvalue_sw)\n",
    "    if pvalue_sw < alpha:\n",
    "        condition.append('Not normal')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "        # result.append('Passed')\n",
    "\n",
    "    # jarque-bera test\n",
    "    jb_name = [\"Jarque-Bera\", \"Chi^2\", \"Skew\", \"Kurtosis\"]\n",
    "    jb_statistic = sms.jarque_bera(data)\n",
    "    jb = dict(zip(jb_name, jb_statistic))\n",
    "    pvalue_jb = jb['Chi^2']\n",
    "    # category_names.append('Residuals')\n",
    "    tests_names.append('Jarque-Bera')\n",
    "    pvalue.append(pvalue_jb)\n",
    "    if pvalue_jb < alpha:\n",
    "        condition.append('Not normal')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "        # result.append('Passed')\n",
    "    \n",
    "    # D’Agostino and Pearson\n",
    "    dagp = stats.normaltest(data)\n",
    "    pvalue_dagp = dagp.pvalue\n",
    "    # category_names.append('Residuals')\n",
    "    tests_names.append('D’Agostino-Pearson')\n",
    "    pvalue.append(pvalue_dagp)\n",
    "    if pvalue_dagp < alpha:\n",
    "        condition.append('Not normal')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "        # result.append('Passed')\n",
    "\n",
    "    pvalue = [np.round(i, 4) for i in pvalue]\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        # 'Category': category_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "        # 'Result': result\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75fc5c1-4bd4-4083-a3ff-f9666c0293ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lr_residuals_mean_ttest(resid, alpha=0.05):\n",
    "\n",
    "    category_names = []\n",
    "    tests_names = []\n",
    "    pvalue = []\n",
    "    condition = []\n",
    "    # result = []\n",
    "    \n",
    "    # mean by student\n",
    "    stmn = stats.ttest_1samp(resid, popmean=0)\n",
    "    pvalue_stmn = stmn.pvalue\n",
    "    # category_names.append('Residuals')\n",
    "    tests_names.append('One Sample t-test')\n",
    "    pvalue.append(pvalue_stmn)\n",
    "    if pvalue_stmn < alpha:\n",
    "        condition.append('Mean not equals zero')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('Mean equals zero')\n",
    "        # result.append('Passed')\n",
    "\n",
    "    pvalue = [np.round(i, 4) for i in pvalue]\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        # 'Category': category_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "        # 'Result': result\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b83352b-be24-4a9a-a880-905188f8e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lr_heteroscedasticity(model, alpha=0.05):\n",
    "\n",
    "    # category_names = []\n",
    "    tests_names = []\n",
    "    pvalue = []\n",
    "    condition = []\n",
    "    # result = []\n",
    "\n",
    "    resid = model.resid\n",
    "    exogs = model.model.exog\n",
    "\n",
    "    # white test\n",
    "    w_name = [\n",
    "        'Test Statistic', 'p_value',\n",
    "        'F Statistic', 'f p_value'\n",
    "    ]\n",
    "    w_statistic = sms.het_white(resid,  exogs)\n",
    "    w_test = dict(zip(w_name, w_statistic))\n",
    "    pvalue_w_test = w_test['p_value']\n",
    "    # category_names.append('Residuals')\n",
    "    tests_names.append(\"White's\")\n",
    "    pvalue.append(pvalue_w_test)\n",
    "    if pvalue_w_test < alpha:\n",
    "        condition.append('Heteroscedasticity')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('Homoscedasticity')\n",
    "        # result.append('Passed')\n",
    "    \n",
    "    # breusch-pagan-lagrange test\n",
    "    bpl_name = [\n",
    "        'Lagrange multiplier statistic',\n",
    "        'p_value', 'f_value', 'f_p_value'\n",
    "    ]\n",
    "    bpl_statistic = sm.stats.het_breuschpagan(resid, exogs)\n",
    "    bpl = dict(zip(bpl_name, bpl_statistic))\n",
    "    pvalue_bpl = bpl['p_value']\n",
    "    # category_names.append('Residuals')\n",
    "    tests_names.append('Breusch-Pagan-Lagrange')\n",
    "    pvalue.append(pvalue_bpl)\n",
    "    if pvalue_bpl < alpha:\n",
    "        condition.append('Heteroscedasticity')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('Homoscedasticity')\n",
    "        # result.append('Passed')\n",
    "    \n",
    "    # goldfeld-quandt test\n",
    "    gq_name = [\"F statistic\", \"p_value\"]\n",
    "    gq_statistic = sms.het_goldfeldquandt(resid, exogs, drop=0.2)\n",
    "    gq = dict(zip(gq_name, gq_statistic))\n",
    "    pvalue_gq = gq['p_value']\n",
    "    # category_names.append('Residuals')\n",
    "    tests_names.append('Goldfeld-Quandt')\n",
    "    pvalue.append(pvalue_gq)\n",
    "    if pvalue_gq < alpha:\n",
    "        condition.append('Heteroscedasticity')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('Homoscedasticity')\n",
    "        # result.append('Passed')\n",
    "\n",
    "    pvalue = [np.round(i, 4) for i in pvalue]\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        # 'Category': category_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "        # 'Result': result\n",
    "    })\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92017335-bcc1-47dc-824b-5bf3fee2ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lr_r_squared(model, alpha):\n",
    "\n",
    "    # category_names = []\n",
    "    tests_names = []\n",
    "    pvalue = []\n",
    "    condition = []\n",
    "    # result = []\n",
    "    \n",
    "    df1 = int(model.df_model)\n",
    "    df2 = int(model.nobs - model.df_model - 1)\n",
    "    fvalue = model.fvalue\n",
    "    fpvalue = 1 - stats.f.cdf(fvalue, df1, df2, loc=0, scale=1)\n",
    "    # category_names.append('Model')\n",
    "    tests_names.append('Fisher Criterion')\n",
    "    pvalue.append(fpvalue)\n",
    "    if fpvalue < alpha:\n",
    "        condition.append('Significant')\n",
    "        # result.append('Passed')\n",
    "    else:\n",
    "        condition.append('Insignificant')\n",
    "        # result.append('Not passed')\n",
    "\n",
    "    pvalue = [np.round(i, 4) for i in pvalue]\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        # 'Category': category_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "        # 'Result': result\n",
    "    })\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50afa62b-8167-416c-8f30-873460cdfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lr_autocorrelation(model, alpha=0.05):\n",
    "\n",
    "    # category_names = []\n",
    "    tests_names = []\n",
    "    pvalue = []\n",
    "    condition = []\n",
    "    # result = []\n",
    "    \n",
    "    # residuals calculate\n",
    "    resid = model.resid\n",
    "\n",
    "    # durbin-watson\n",
    "    # category_names.append('Residuals')\n",
    "    tests_names.append('Durbin-Watson (s)')\n",
    "    dw_test = sm.stats.stattools.durbin_watson(resid)\n",
    "    if (1.5 < dw_test < 2.5):\n",
    "        condition.append('No autocorrelation')\n",
    "        # result.append('Passed')\n",
    "    else:\n",
    "        condition.append('Autocorrelation')\n",
    "        # result.append('Not Passed')\n",
    "    dw_test = np.round(dw_test, 2)\n",
    "    pvalue.append(dw_test)\n",
    "\n",
    "    # Breusch-Godfrey\n",
    "    bg_test = sm.stats.diagnostic.acorr_breusch_godfrey(model, nlags=3)\n",
    "    bg_name = [\n",
    "        'Lagrange multiplier test statistic',\n",
    "        'p_value', 'F statistic', 'fp_value'\n",
    "    ]\n",
    "    bg = dict(zip(bg_name, bg_test))\n",
    "    pvalue_bg = bg['p_value']\n",
    "    # category_names.append('Residuals')\n",
    "    tests_names.append('Breusch-Godfrey')\n",
    "    if pvalue_bg < alpha:\n",
    "        condition.append('Autocorrelation')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('No autocorrelation')\n",
    "        # result.append('Passed')\n",
    "    pvalue_bg = np.round(pvalue_bg, 4)\n",
    "    pvalue.append(pvalue_bg)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        # 'Category': category_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "        # 'Result': result\n",
    "    })\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbdd5ad-1350-43b2-9f49-d4da66f9853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vif(X):\n",
    "    \n",
    "    # category_names = []\n",
    "    tests_names = []\n",
    "    pvalue = []\n",
    "    condition = []\n",
    "    # result = []\n",
    "    \n",
    "    vf = vif(X)['VIF'].iloc[0]\n",
    "    # category_names.append('Predictors')\n",
    "    tests_names.append('VIF (s)')\n",
    "    pvalue.append(vf)\n",
    "    if vf > 10:\n",
    "        condition.append('Multicollinearity')\n",
    "        # result.append('Not passed')\n",
    "    else:\n",
    "        condition.append('No multicollinearity')\n",
    "        # result.append('Passed')\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        # 'Category': category_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "        # 'Result': result\n",
    "    })\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4615edb-e389-4fa4-820c-aba814a59ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilcoxon(data, alpha=0.05):\n",
    "\n",
    "    tests_names = []\n",
    "    pvalue = []\n",
    "    condition = []\n",
    "\n",
    "    tests_names.append('One Sample Wilcoxon test')\n",
    "    w, p_value = scipy.stats.wilcoxon(data, alternative='greater')\n",
    "    pvalue.append(p_value)\n",
    "\n",
    "    if p_value < alpha:\n",
    "        condition.append('Mean not equals zero')\n",
    "    else:\n",
    "        condition.append('Mean equals zero')\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a4ea9-bb42-413f-ba17-43b81197a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_sided_bootstrap(\n",
    "        data, value, statistic=np.mean, n_bootstrap=10000, confidence_level=0.95):\n",
    "\n",
    "    '''\n",
    "    Null hypothesis: value is real mean (or statistic) of data\n",
    "    '''\n",
    "    \n",
    "    bootstrap = ci_bootstrap(\n",
    "        data=data, statistic=statistic, n_bootstrap=n_bootstrap,\n",
    "        confidence_level=confidence_level)\n",
    "\n",
    "    ci_min = bootstrap['ci_min']\n",
    "    ci_max = bootstrap['ci_max']\n",
    "\n",
    "    if ci_min <= value <= ci_max:\n",
    "        # we can't reject hypothesis that 'value' is real mean\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a797370b-8244-47e2-bef3-287fbd178970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lr_residuals_mean_bootstrap(resid, n_bootstrap=10000, alpha=0.05):\n",
    "\n",
    "    condition = []\n",
    "    ci_level = 1 - alpha\n",
    "    res = test_one_sided_bootstrap(\n",
    "        resid, value=0, statistic=np.mean, n_bootstrap=n_bootstrap, confidence_level=ci_level)\n",
    "\n",
    "    if res:\n",
    "        condition.append('Mean equals zero')\n",
    "    else:\n",
    "        condition.append('Mean not equals zero')\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': 'One Sample Bootstrap test (s)',\n",
    "        'P or Statistic (s)': n_bootstrap,\n",
    "        'Condition': condition,\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7951a058-c0fa-4868-b507-0ecd93f2d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_diagnostics(model, X, alpha=0.05):\n",
    "\n",
    "    # residuals calculate\n",
    "    resid = model.resid\n",
    "    # ramsey's reset\n",
    "    results_ramsey_reset = test_ramsey_reset(model, alpha=0.05)\n",
    "    results_ramsey_reset['Category'] = 'Model'\n",
    "    # r-squared significance\n",
    "    results_r = test_lr_r_squared(model, alpha=alpha)\n",
    "    results_r['Category'] = 'Model'\n",
    "    # vif\n",
    "    results_vif = test_vif(X)\n",
    "    results_vif['Category'] = 'Predictors'\n",
    "    # multicollinearity test\n",
    "    results_mult = test_lr_multicollinearity(model)\n",
    "    results_mult['Category'] = 'Predictors'\n",
    "    # residuals mean t-test\n",
    "    results_resid_mean = test_lr_residuals_mean_ttest(resid, alpha=alpha)\n",
    "    results_resid_mean['Category'] = 'Residuals'\n",
    "    # residuals mean wilcoxon test\n",
    "    results_resid_mean_wilcoxon = wilcoxon(resid, alpha=alpha)\n",
    "    results_resid_mean_wilcoxon['Category'] = 'Residuals'\n",
    "    # residuals mean bootstrap test\n",
    "    results_resid_mean_bootstrap = test_lr_residuals_mean_bootstrap(resid, alpha=alpha)\n",
    "    results_resid_mean_bootstrap['Category'] = 'Residuals'\n",
    "    # residuals normality test\n",
    "    results_resid = test_normality(resid, alpha=alpha)\n",
    "    results_resid['Category'] = 'Residuals'\n",
    "    # heteroscedasticity test\n",
    "    results_hetero = test_lr_heteroscedasticity(model, alpha=alpha)\n",
    "    results_hetero['Category'] = 'Residuals'\n",
    "    # cook's distance\n",
    "    results_cd = test_lr_cooks_distance(model)\n",
    "    results_cd['Category'] = 'Residuals'\n",
    "    # autocorrelation\n",
    "    results_ac = test_lr_autocorrelation(model, alpha=0.05)\n",
    "    results_ac['Category'] = 'Residuals'\n",
    "\n",
    "    results_list = [\n",
    "        results_ramsey_reset, results_r, results_vif, results_mult,\n",
    "        results_cd, results_resid_mean, results_resid_mean_wilcoxon,\n",
    "        results_resid_mean_bootstrap, results_resid, results_hetero, results_ac\n",
    "    ]\n",
    "\n",
    "    results = pd.concat(results_list, axis=0)\n",
    "    results = results.reset_index(drop=True)\n",
    "    # move column 'Category' to position after column 'Test'\n",
    "    col = results.pop('Category')\n",
    "    idx = results.columns.get_loc('Test')\n",
    "    results.insert(idx+1, 'Category', col)\n",
    "\n",
    "    # round values\n",
    "    round_to_zero_list = [\n",
    "        \"Cook's Distance (s)\", 'One Sample Bootstrap test (s)'\n",
    "    ]\n",
    "    for i in results.index:\n",
    "        value = results.loc[i, 'P or Statistic (s)']\n",
    "        if results.loc[i, 'Test'] not in round_to_zero_list:\n",
    "            results.loc[i, 'P or Statistic (s)'] = '{:,.4f}'.format(value)\n",
    "        else:\n",
    "            results.loc[i, 'P or Statistic (s)'] = '{:.0f}'.format(value)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee22e2f-cf10-4e91-b83d-414d7240c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cooksd_outliers_idxs(model, data):\n",
    "    df = data.copy()\n",
    "    # calculate cooks distance for all elements\n",
    "    cooksd = model.get_influence().cooks_distance[0]\n",
    "    # border\n",
    "    cooksd_border = 4/len(cooksd)\n",
    "    df['cooksd'] = cooksd\n",
    "    df['outlier'] = (df['cooksd'] > cooksd_border).astype(int)\n",
    "    outlier_number = df['outlier'].sum()\n",
    "    outlier_idxs = df[df['outlier'] == 1].index.tolist()\n",
    "    return outlier_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cec219-3971-4ecb-8907-5fc3ede33e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_coef(model, orient='v', figsize=(4, 6)):\n",
    "\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    s=15\n",
    "    coeff_df = pd.DataFrame(model.params, columns=['coeff'])\n",
    "    conf_df = model.conf_int().rename(columns={0: 'min_ci', 1: 'max_ci'})\n",
    "    conf_plot = pd.concat([coeff_df, conf_df], axis=1)\n",
    "    conf_plot = conf_plot.iloc[1:]\n",
    "    conf_plot = conf_plot.sort_values('coeff', ascending=False, key=abs)\n",
    "    \n",
    "    if orient == 'h':\n",
    "        ax = sns.scatterplot(\n",
    "            data=conf_plot,\n",
    "            x=conf_plot.index,\n",
    "            y='coeff',\n",
    "            s=s,\n",
    "            alpha=0.9\n",
    "        )\n",
    "        # errobars\n",
    "        yerr = ([conf_plot['coeff'] - conf_plot['min_ci'],\n",
    "                 conf_plot['max_ci'] - conf_plot['coeff']])\n",
    "        plt.errorbar(\n",
    "            x=conf_plot.index.tolist(),\n",
    "            y=conf_plot['coeff'],\n",
    "            yerr=yerr, fmt='none', elinewidth=1, capsize=1.2, alpha=0.9)\n",
    "\n",
    "        plt.axhline(0, color=palette[0], lw=0.75, alpha=0.25)\n",
    "    \n",
    "        plt.ylabel('Coefficients')\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "    if orient == 'v':\n",
    "        ax = sns.scatterplot(\n",
    "            data=conf_plot,\n",
    "            x='coeff',\n",
    "            y=conf_plot.index,\n",
    "            s=s,\n",
    "            alpha=0.9\n",
    "        )\n",
    "        # errobars\n",
    "        xerr = ([conf_plot['coeff'] - conf_plot['min_ci'],\n",
    "                 conf_plot['max_ci'] - conf_plot['coeff']])\n",
    "        plt.errorbar(\n",
    "            x=conf_plot['coeff'], y=conf_plot.index.tolist(),\n",
    "            xerr=xerr, fmt='none', elinewidth=1,\n",
    "            capsize=1.2, capthick=1, alpha=0.9\n",
    "        )\n",
    "        plt.axvline(\n",
    "            0, ymin=0.02, ymax=0.98, color=palette[0], lw=0.5, alpha=0.75)\n",
    "\n",
    "    yticks = conf_plot.index\n",
    "    ylabels = [str.lower(i) for i in yticks]\n",
    "    plt.yticks([])\n",
    "    plt.xticks(color=alpha_color(palette[0], 0.85))\n",
    "    plt.ylabel(None)\n",
    "    plt.xlabel(None)\n",
    "    plt.title(' ', loc='left', pad=40)\n",
    "    ax.tick_params(\n",
    "        bottom=False,\n",
    "        axis='x', which='major', labelsize=7, pad=5)\n",
    "    ax.tick_params(axis='y', pad=10)\n",
    "    ax.spines[['bottom', 'top', 'left', 'right']].set_visible(True)\n",
    "    ax.spines[['bottom', 'top', 'left', 'right']].set_linewidth(0.5)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe96fb4-afee-4dec-9b3a-da12d319e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_residuals(model, data, target):\n",
    "    # fitted values\n",
    "    y_pred = model.fittedvalues\n",
    "    #  Plot\n",
    "    ax = sns.residplot(\n",
    "        x=y_pred, y=target, data=data,\n",
    "        lowess=True,\n",
    "        scatter_kws={\n",
    "            'alpha': 0.9,\n",
    "            's': 10,\n",
    "            'ec': '0.85',\n",
    "            'linewidth': 0.35\n",
    "        },\n",
    "        line_kws={\n",
    "            'color': palette[1],\n",
    "            'lw': 1.5,\n",
    "            'alpha': 0.35\n",
    "        })\n",
    "    # Titel and labels\n",
    "    ax.set_title('Residuals vs Predicted')\n",
    "    ax.set_xlabel('Fitted values')\n",
    "    ax.set_ylabel('Residuals')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e84f71-6e40-4c0a-86b4-b4f53b14faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_leverage_resid_square(model, figsize):\n",
    "\n",
    "    infl = model.get_influence()\n",
    "    leverage = infl.hat_matrix_diag\n",
    "    resid = zscore(infl.resid)\n",
    "    resid_square = resid**2\n",
    "    labels = model.model.data.row_labels\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    plt.scatter(x=resid_square, y=leverage)\n",
    "    for i, txt in enumerate(labels):\n",
    "        ax.annotate(txt, (resid_square[i], leverage[i]), fontsize=7)\n",
    "    ax.set_xlabel('Normalized Residuals Squared')\n",
    "    ax.set_ylabel('Levarage')\n",
    "    ax.set_title('Levarage vs. Normalized Residuals Squared')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b71946-9bd2-4e45-b379-9f70b974215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_column_iqr(data, feature, scale=1.5):\n",
    "\n",
    "    df = data.copy()\n",
    "\n",
    "    q1 = df[feature].quantile(0.25)\n",
    "    q3 = df[feature].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_boundary = q1 - scale*iqr\n",
    "    upper_boundary = q3 + scale*iqr\n",
    "    condition = ((df[feature] < lower_boundary) |\n",
    "                 (df[feature] > upper_boundary))\n",
    "    df[feature+'_is_out'] = condition.astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65350fc3-7b47-4452-ab66-21b6269ecd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_enet_features(X, y, alphas):\n",
    "\n",
    "    X_ = X.copy()\n",
    "    keys = [\n",
    "        'score', 'alpha', 'features_num',\n",
    "        'vif_max_value', 'features_list'\n",
    "    ]\n",
    "    res_dct = {key:[] for key in keys}\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        res_dct['alpha'].append(alpha)\n",
    "        # score \n",
    "        estimator = ElasticNet(alpha=alpha, random_state=seed)\n",
    "        estimator.fit(X_, y)\n",
    "        y_pred = estimator.predict(X_)\n",
    "        score = mean_squared_error(y, y_pred, squared=False)\n",
    "        res_dct['score'].append(score)\n",
    "        # features and features number\n",
    "        summary = pd.DataFrame({\n",
    "            'feature': estimator.feature_names_in_,\n",
    "            'coeff': estimator.coef_\n",
    "        })\n",
    "        summary = summary.loc[summary['coeff'] != 0]\n",
    "        features = summary['feature'].tolist()\n",
    "        features_len = len(summary)\n",
    "        res_dct['features_list'].append(features)\n",
    "        res_dct['features_num'].append(features_len)\n",
    "        # vif estimation\n",
    "        vif_df = vif(X_[features])\n",
    "        if vif_df.empty:\n",
    "            vif_max_value = 0\n",
    "        else:\n",
    "            vif_max_value = vif_df.iloc[0,0]\n",
    "        vif_max_value = np.round(vif_max_value, 1)\n",
    "        res_dct['vif_max_value'].append(vif_max_value)\n",
    "    \n",
    "    return res_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d1a2c-76af-4145-90d9-fab40e4a284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sum(data, sum_column, columns, return_diff=False):\n",
    "    \n",
    "    all_columns = columns.copy()\n",
    "    all_columns.append(sum_column)\n",
    "    df = data[all_columns].copy()\n",
    "    df['diff'] = df[sum_column]\n",
    "    \n",
    "    for column in columns:\n",
    "        df['diff'] = df['diff'] - df[column]\n",
    "    cond = df['diff'].any() != 0\n",
    "    \n",
    "    if cond:\n",
    "        if return_df:\n",
    "            result = df.loc[df['diff'] != 0]\n",
    "            result = result.sort_values(\n",
    "                'diff', ascending=False, key=abs)\n",
    "            return result\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93a4df-3e50-4fe2-a794-799a39e7d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_garage_discrepancy(data, features_garage):\n",
    "    df = data[features_garage].copy()\n",
    "    \n",
    "    garage_len_check(df, features_garage)\n",
    "    garage_na_zero_check(test, features_garage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb02a1-ec59-46e5-9e90-99cdd5648faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def garage_len_check(df, features_garage):\n",
    "    condition = (len(df[df['garagearea'] == 0])\n",
    "                 == len(df[df['garagecars'] == 0])\n",
    "                 == len(df[df['garagecond'] == 'NA'])\n",
    "                 == len(df[df['garagefinish'] == 'NA'])\n",
    "                 == len(df[df['garagequal'] == 'NA'])\n",
    "                 == len(df[df['garagetype'] == 'NA']))\n",
    "    if condition:\n",
    "        print('Garage Features NA-zeroes length: No discrepancy')\n",
    "    else:\n",
    "        print('Garage Features NA-zeroes length: Discrepancy detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2926dc-5f15-4a23-b200-41c88da5965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def garage_na_zero_check(data, features_garage):\n",
    "    df = data.copy()\n",
    "    loc_r = ((df['garagecars'] == 0)\n",
    "             | (df['garagearea'] == 0)\n",
    "             | (df['garagecond'] == 'NA')\n",
    "             | (df['garagefinish'] == 'NA')\n",
    "             | (df['garagequal'] == 'NA')\n",
    "             | (df['garagetype'] == 'NA'))\n",
    "\n",
    "    check_na_vars = [\n",
    "        'garagecars', 'garagearea', 'garagecond',\n",
    "        'garagefinish', 'garagequal', 'garagetype'\n",
    "    ]\n",
    "    train_garage_na = df.loc[loc_r, check_na_vars]\n",
    "    values_dict = {0: 'NA'}\n",
    "\n",
    "    for feature in check_na_vars:\n",
    "        loc = (train_garage_na[feature] == 0, feature)\n",
    "        train_garage_na.loc[loc] = train_garage_na.loc[loc].map(values_dict)\n",
    "\n",
    "    df = train_garage_na.copy()\n",
    "    df['is_equal'] = df.eq(df.iloc[:, 0], axis=0).all(1).astype(int)\n",
    "    equal_sum = df['is_equal'].sum()\n",
    "\n",
    "    if equal_sum == len(df):\n",
    "        print('Garage Features NA-zeroes: No discrepancy')\n",
    "        return None\n",
    "    else:\n",
    "        print('Garage Features NA-zeroes: Discrepancy detected')\n",
    "        loc = df['is_equal'] == 0, df.columns != 'is_equal'\n",
    "        result = df.loc[loc].copy()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a51358-427d-4a08-ac4b-d706891786d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bsmt_discrepancy(data, features_bsmt):\n",
    "    df = data[features_bsmt].copy()\n",
    "    df['bsmnt_check'] = (df['totalbsmtsf']\n",
    "                         - df['bsmtunfsf']\n",
    "                         - df['bsmtfinsf_second']\n",
    "                         - df['bsmtfinsf_first'])\n",
    "\n",
    "    condition = df['bsmnt_check'].any()\n",
    "    if condition:\n",
    "        print('Basement Features: Discrepancy detected')\n",
    "        return df.loc[df['bsmnt_check'] != 0, :]\n",
    "    else:\n",
    "        print('Basement Features: No discrepancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7709ac8-6862-4e96-acf0-1475ecaf6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_feet_check_discrepancy(data, features_square):\n",
    "    features = features_square.copy()\n",
    "    features.extend(['masvnrtype', 'poolqc'])\n",
    "    df = data[features].copy()\n",
    "    # livarea\n",
    "    df['livarea_check'] = (df['grlivarea']\n",
    "                           - df['first_flrsf']\n",
    "                           - df['second_flrsf']\n",
    "                           - df['lowqualfinsf'])\n",
    "    condition = df['livarea_check'].any()\n",
    "    if condition:\n",
    "        print('Livarea Features: Discrepancy detected')\n",
    "        return df.loc[df['bsmnt_check'] != 0, :]\n",
    "    else:\n",
    "        print('Livarea Features: No discrepancy')\n",
    "    # masvnrtype\n",
    "    cond1 = ((df['masvnrtype'] == 'NA')\n",
    "             & df['masvnrarea'] != 0)\n",
    "    cond2 = ((df['masvnrarea'] == 0)\n",
    "             & (df['masvnrtype'] != 'NA'))\n",
    "    loc_r = (cond1 | cond2)\n",
    "    train_masvnr_unaccord = df[['masvnrarea', 'masvnrtype']].loc[loc_r, :]\n",
    "    if train_masvnr_unaccord.empty:\n",
    "        print('Masvnrtype Features: No discrepancy')\n",
    "    else:\n",
    "        print('Masvnrtype Features: Discrepancy detected')\n",
    "        return train_masvnr_unaccord\n",
    "    # poolarea\n",
    "    loc = ((df['poolarea'] == 0)\n",
    "       | (df['poolqc'] == 'NA'))\n",
    "    train_poolarea_na = df[['poolarea', 'poolqc']].loc[loc, :]\n",
    "    values_dict = {0: 'NA'}\n",
    "    loc = (train_poolarea_na['poolarea'] == 0, 'poolarea')\n",
    "    train_poolarea_na.loc[loc] = train_poolarea_na.loc[loc].map(values_dict)\n",
    "\n",
    "    df = train_poolarea_na.copy()\n",
    "    df['is_equal'] = df.eq(df.iloc[:, 0], axis=0).all(1).astype(int)\n",
    "    equal_sum = df['is_equal'].sum()\n",
    "\n",
    "    if equal_sum == len(df):\n",
    "        print('Pool Features NA-zeroes: No discrepancy')\n",
    "    else:\n",
    "        print('Pool Features NA-zeroes: Discrepancy detected')\n",
    "        loc = df['is_equal'] == 0, df.columns != 'is_equal'\n",
    "        result = df.loc[loc].copy()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61847bb-24f8-421d-96ce-3bf04cea114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_std_ddof1(x):\n",
    "        return np.std(x, ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbd6910-1de9-43b5-a7b0-a6aa031085d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_check_discrepancy(data, features_year):\n",
    "    df = data[features_year].copy()\n",
    "    if (df['yearremodadd'] < df['yearbuilt']).any():\n",
    "        print('Modernization is earlier than built')\n",
    "    if (df['yrsold'] < df['yearbuilt']).any():\n",
    "        print('Sold earlier than built')\n",
    "    else:\n",
    "        print('Year Features: No discrepancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08405c79-0631-4f97-b193-d0cadc9533f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_evaluation(\n",
    "        X, y, names, estimators, parameters,\n",
    "        n_folds=10, full_results=False):\n",
    "    \n",
    "    results_cv_keys = [\n",
    "        'Model', 'MeanScore', 'StdScore',\n",
    "        'FitTime', 'StdFitTime', 'ScoreTime', 'StdScoreTime',\n",
    "        'HyperSearchTime', 'BestEstimator'\n",
    "    ]\n",
    "    t_t = time.time()\n",
    "    results_cv_dct = {i:[] for i in results_cv_keys}\n",
    "    # results_cv_dct_full = {i:{} for i in names}\n",
    "    cv_dict = {i:None for i in names}\n",
    "    ranges = zip(names, estimators, parameters)\n",
    "    \n",
    "    for name, estimator, params in ranges:\n",
    "        t_st = time.time()\n",
    "        cv = GridSearchCV(\n",
    "            estimator=estimator, \n",
    "            param_grid=params,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            cv=n_folds\n",
    "        )\n",
    "        cv.fit(X, y)\n",
    "        # calculate scores\n",
    "        best_index = cv.best_index_\n",
    "        best_score = cv.cv_results_['mean_test_score'][best_index]\n",
    "        std_score = cv.cv_results_['std_test_score'][best_index]\n",
    "        fit_time = cv.cv_results_['mean_fit_time'][best_index]\n",
    "        std_fit_time = cv.cv_results_['std_fit_time'][best_index]\n",
    "        score_time = cv.cv_results_['mean_score_time'][best_index]\n",
    "        std_score_time = cv.cv_results_['std_score_time'][best_index]\n",
    "        best_estimator = cv.best_estimator_\n",
    "        t_reg = time.time() - t_st\n",
    "        t_reg_format = dt.timedelta(seconds=np.round(t_reg))\n",
    "        t_reg_format = str(t_reg_format)\n",
    "        # list with result values\n",
    "        results_cv_values = [\n",
    "            name, best_score, std_score,\n",
    "            fit_time, std_fit_time, score_time, std_score_time,\n",
    "            t_reg_format, best_estimator\n",
    "        ]\n",
    "        # fill results dict\n",
    "        for key, value in zip(results_cv_keys, results_cv_values):\n",
    "            results_cv_dct[key].append(value)\n",
    "\n",
    "        if full_results:\n",
    "            # results_cv_dct_full[name] = cv.cv_results_\n",
    "            cv_dict[name] = cv\n",
    "        \n",
    "    results_cv = pd.DataFrame(results_cv_dct)\n",
    "    results_cv = results_cv.sort_values('MeanScore', ascending=False)\n",
    "    results_cv = results_cv.reset_index(drop=True)\n",
    "\n",
    "    t_tf = time.time() - t_t\n",
    "    t_tf_format = dt.timedelta(seconds=np.round(t_tf))\n",
    "    t_tf_format = str(t_tf_format)\n",
    "    results_cv['TotalTime'] = t_tf_format\n",
    "    idx = results_cv.columns.get_loc('BestEstimator')\n",
    "    results_cv.insert(\n",
    "        loc=idx, column='TotalTime_1', value=results_cv['TotalTime'])\n",
    "    results_cv = results_cv.drop('TotalTime', axis=1)\n",
    "    results_cv = results_cv.rename(columns={'TotalTime_1': 'TotalTime'})\n",
    "\n",
    "    if full_results:\n",
    "        return results_cv, cv_dict\n",
    "    else:\n",
    "        return results_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545301a8-4606-4130-9813-2dc340113de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(n=5):\n",
    "    hsv_tuples = [(x/n, 0.85*x/n, 0.85*x/n) for x in range(n)]\n",
    "    hex = []\n",
    "    for rgb in hsv_tuples:\n",
    "        rgb = map(lambda x: int(x * 255), colorsys.hsv_to_rgb(*rgb))\n",
    "        hex.append('#%02x%02x%02x' % tuple(rgb))\n",
    "    return hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5edf93-8de7-4f1c-ae5d-83d93a5ff134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hex(x):\n",
    "    color_hex = matplotlib.colors.to_hex(x)\n",
    "    return color_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71280da9-f623-41cb-ae61-048ad1acdbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_display(\n",
    "        features, importance,\n",
    "        top=None, imp_min_level=None, only_features=True):\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importance\n",
    "    })\n",
    "    if imp_min_level is not None:\n",
    "        loc_row = feature_importance['Importance'] > imp_min_level\n",
    "        feature_importance = (feature_importance\n",
    "                              .loc[loc_row, :]\n",
    "                              .sort_values('Importance', ascending=False)\n",
    "                              .reset_index(drop=True))\n",
    "    if top is not None:\n",
    "        feature_importance = (feature_importance\n",
    "                             .sort_values('Importance', ascending=False)\n",
    "                             .reset_index(drop=True))\n",
    "        feature_importance = feature_importance.loc[0:top-1]\n",
    "\n",
    "    if only_features:\n",
    "        feature_importance = feature_importance['Feature']\n",
    "        \n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9e648-e235-4678-9a74-7a1b10589b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_t_distribution(\n",
    "        data=None, mean=None, std=None, n=None, confidence_level=0.95):\n",
    "\n",
    "    if data is not None:\n",
    "        arr = np.array(data)\n",
    "        n = len(arr)\n",
    "        mean = np.mean(arr)\n",
    "        se = scipy.stats.sem(arr)\n",
    "        \n",
    "    if mean and std and n is not None:\n",
    "        se = std / np.sqrt(n)\n",
    "\n",
    "    t = scipy.stats.t.ppf((1+confidence_level) / 2, n-1)\n",
    "    margin = t * se\n",
    "    ci_min = mean - margin\n",
    "    ci_max = mean + margin\n",
    "\n",
    "    return_dct = {\n",
    "        'min': ci_min,\n",
    "        'max': ci_max,\n",
    "        'mean': mean,\n",
    "        'margin': margin,\n",
    "        't': t\n",
    "    }\n",
    "    return return_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea2af0-bf1b-4a99-9c3f-6bf68590da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_bootstrap(\n",
    "        data, statistic=np.mean, method='BCa', n_bootstrap=1000,\n",
    "        confidence_level=0.95, random_state=42):\n",
    "    '''\n",
    "    Returns: dict(statistic, std, ci_min, ci_max, margin)\n",
    "    '''\n",
    "    data_ = (data,)\n",
    "    bootstrap = scipy.stats.bootstrap(\n",
    "        data=data_,\n",
    "        statistic=statistic,\n",
    "        method=method,\n",
    "        n_resamples=n_bootstrap,\n",
    "        confidence_level=confidence_level,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    ci_min = bootstrap.confidence_interval[0]\n",
    "    ci_max = bootstrap.confidence_interval[1]\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        stat = data.apply(statistic)\n",
    "        stat = np.array(stat)\n",
    "        std = np.array(np.std(data, ddof=1))\n",
    "    else:\n",
    "        stat = statistic(data)\n",
    "        std = np.std(data, ddof=1)\n",
    "\n",
    "    proximate_margin = bootstrap.standard_error*1.96\n",
    "\n",
    "    return_dct = {\n",
    "        'statistic': stat,\n",
    "        'std': std,\n",
    "        'ci_min': ci_min,\n",
    "        'ci_max': ci_max,\n",
    "        'proxi_margin': proximate_margin\n",
    "    }\n",
    "    \n",
    "    return return_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dad8db-2b14-47d8-8319-d808e9923eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointplot(\n",
    "        x, y, err, figsize=(3,4), s=40, fmt='none',\n",
    "        linestyle='none', capsize=2, capthick=1, linewidth=1, ylim=None,\n",
    "        scatter_kwargs={}, err_kwargs={}):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.figure(figsize=(3,4))\n",
    "    plt.scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        s=40,\n",
    "        **scatter_kwargs\n",
    "    );\n",
    "    plt.errorbar(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        yerr=err,\n",
    "        fmt=fmt,\n",
    "        linestyle=linestyle,\n",
    "        capsize=capsize,\n",
    "        capthick=capthick,\n",
    "        linewidth=linewidth,\n",
    "        **err_kwargs\n",
    "    );\n",
    "    xmin, xmax, _, _ = plt.axis()\n",
    "    plt.xlim(xmin-0.5, xmax+0.5)\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0313e35c-9a65-402d-a34c-4feced3ebfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legend_customized(\n",
    "        figure, legend_x=200, legend_y=16.5, ncols=1, fontsize=8, titlesize=9,\n",
    "        alignment='left', ax=None, **kwargs):\n",
    "    \n",
    "    fig_x = (figure.get_size_inches()*figure.dpi)[0]\n",
    "    fig_y = (figure.get_size_inches()*figure.dpi)[1]\n",
    "\n",
    "    if ncols == 1:\n",
    "        legend_x = (fig_x + legend_x) / fig_x\n",
    "    else:\n",
    "        legend_x = (fig_x + 0.1*legend_x) / fig_x\n",
    "    legend_y = (fig_x + legend_y) / fig_x\n",
    "\n",
    "    ax = ax or plt\n",
    "    ax.legend(\n",
    "        fontsize=fontsize, ncols=ncols, \n",
    "        title_fontproperties={'size': titlesize}, alignment=alignment,\n",
    "        bbox_to_anchor=(legend_x, legend_y), **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193be4c4-c474-456b-a77d-47e0129f0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gridplot(\n",
    "        data, features, target=None, figsize=None, ncols=3, kind='reg',\n",
    "        plot_shape='rectangle', markersize=15, hscale=1, pscale=1, regplot_kwargs={},\n",
    "        pointplot_kwargs={}, scatterplot_kwargs={}, histplot_kwargs={}):\n",
    "\n",
    "    nrows = math.ceil(len(features) / ncols)\n",
    "    nplots = np.arange(1, len(features)+1)\n",
    "\n",
    "    if plot_shape == 'square':\n",
    "        whscale=(2,2)\n",
    "    if plot_shape == 'rectangle':\n",
    "        whscale=(4,2.5)\n",
    "\n",
    "    if figsize is not None:\n",
    "        figsize = figsize\n",
    "    else:\n",
    "        width = whscale[0] * ncols\n",
    "        height = whscale[1] * nrows\n",
    "        figsize_width = width * pscale\n",
    "        figsize_height = height * pscale\n",
    "        figsize = (figsize_width, figsize_height)\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    if kind == 'reg':\n",
    "        for feature, plot in zip(features, nplots):\n",
    "            plt.subplot(nrows, ncols, plot)\n",
    "            sns.regplot(\n",
    "                data=data,\n",
    "                x=feature,\n",
    "                y=target,\n",
    "                scatter_kws={\n",
    "                    'ec': '#606060',\n",
    "                    's': markersize,\n",
    "                    'alpha': 0.9\n",
    "                },\n",
    "                **regplot_kwargs\n",
    "            )\n",
    "            plt.ylabel(None)\n",
    "\n",
    "    if kind == 'point':\n",
    "        for feature, plot in zip(features, nplots):\n",
    "            plt.subplot(nrows, ncols, plot)\n",
    "            sns.pointplot(\n",
    "                data=data,\n",
    "                x=feature,\n",
    "                y=target,\n",
    "                markersize=markersize,\n",
    "                linestyle='none',\n",
    "                capsize=0.031,\n",
    "                err_kws={'lw': 0.81*pscale},\n",
    "                **pointplot_kwargs\n",
    "            )\n",
    "            plt.ylabel(None)\n",
    "            plt.xticks(rotation=45)\n",
    "\n",
    "    if kind == 'hist':\n",
    "        for feature, plot in zip(features, nplots):\n",
    "            plt.subplot(nrows, ncols, plot)\n",
    "            sns.histplot(\n",
    "                data=data,\n",
    "                x=feature,\n",
    "                alpha=0.95,\n",
    "                **histplot_kwargs\n",
    "            )\n",
    "            plt.ylabel(None)\n",
    "\n",
    "    if kind == 'scatter':\n",
    "        for feature, plot in zip(features, nplots):\n",
    "            plt.subplot(nrows, ncols, plot)\n",
    "            sns.scatterplot(\n",
    "                data=data,\n",
    "                x=feature,\n",
    "                y=target,\n",
    "                s=markersize,\n",
    "                **scatter_kwargs\n",
    "            )\n",
    "            plt.ylabel(None)\n",
    "        \n",
    "    plt.subplots_adjust(hspace=0.4*hscale)\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14797867-2b83-4c80-a058-1ea58cdfee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_diagnostics(model, data, target, figsize=(11, 12)):\n",
    "\n",
    "    resid = model.resid\n",
    "    y_pred = model.fittedvalues\n",
    "    \n",
    "    f = plt.figure(figsize=figsize)\n",
    "    spec = f.add_gridspec(4, 2, height_ratios=[2, 2, 1, 1])\n",
    "    \n",
    "    # plot #1\n",
    "    ax = f.add_subplot(spec[0, :])\n",
    "    ax.scatter(x=model.model.endog, y=y_pred, **scatter)\n",
    "    ax.plot(\n",
    "        model.model.endog, model.model.endog, linestyle=':', linewidth=1.5,\n",
    "        color=palette[1], alpha=0.5)\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.set_ylabel('Predicred')\n",
    "    ax.tick_params(labelsize=7)\n",
    "    \n",
    "    #plot #2\n",
    "    ax = f.add_subplot(spec[1, :])\n",
    "    sns.residplot(\n",
    "            x=y_pred, y=target, data=data,\n",
    "            lowess=True,\n",
    "            scatter_kws={\n",
    "                'alpha': 1,\n",
    "                'ec': '#FDFDFD',\n",
    "                'linewidths': 0.15\n",
    "            },\n",
    "            line_kws={\n",
    "                'ls': ':',\n",
    "                'color': palette[1],\n",
    "                'lw': 1.5,\n",
    "                'alpha': 1\n",
    "            },\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Residuals')\n",
    "    ax.tick_params(labelsize=7)\n",
    "    \n",
    "    # plot #3\n",
    "    ax = f.add_subplot(spec[2, 0])\n",
    "    ax.hist(resid, bins=50)\n",
    "    ax.set_xlabel('Residuals')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.tick_params(labelsize=7)\n",
    "    \n",
    "    # plot #4\n",
    "    ax = f.add_subplot(spec[2, 1])\n",
    "    sm.qqplot(resid, line='s', ax=ax)\n",
    "    ax.get_lines()[0].set_marker('.')\n",
    "    ax.get_lines()[1].set_color(palette[1])\n",
    "    ax.get_lines()[1].set_linestyle(':')\n",
    "    ax.get_lines()[1].set_alpha(1)\n",
    "    ax.set_xlabel('Theoretical quant.')\n",
    "    ax.set_ylabel('Sample quant.')\n",
    "    ax.tick_params(labelsize=7)\n",
    "    \n",
    "    # plot #5\n",
    "    ax = f.add_subplot(spec[3, :])\n",
    "    # calculations\n",
    "    infl = model.get_influence()\n",
    "    leverage = infl.hat_matrix_diag\n",
    "    resid_z = zscore(infl.resid)\n",
    "    resid_square = resid_z**2\n",
    "    # plot\n",
    "    ax.scatter(x=resid_square, y=leverage, **scatter)\n",
    "    ax.set_xlabel('Normalized Residuals Squared')\n",
    "    ax.set_ylabel('Levarage')\n",
    "    ax.tick_params(labelsize=7)\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a77658-e330-4480-b400-b1830cbe4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadit(name, dir='files'):\n",
    "    if dir != 'files':\n",
    "        dir = f'files/{dir}'\n",
    "    result = pd.read_pickle(f'{dir}/{name}.pkl')\n",
    "    return result\n",
    "\n",
    "def saveit(file, name, dir='files'):\n",
    "    if dir != 'files':\n",
    "        dir = f'files/{dir}'\n",
    "    # check if dir exists and create it if not\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "    # save file\n",
    "    filehandler = open(f'{dir}/{name}.pkl', 'wb') \n",
    "    pickle.dump(file, filehandler)\n",
    "    filehandler.close()\n",
    "\n",
    "def savefig(name, dir='img', format='png', dpi=100, transparent=True,  figure=None, **kwargs):\n",
    "    '''\n",
    "    Saves figure as PNG to 'img/' dir\n",
    "    '''\n",
    "    if not figure:\n",
    "       figure = fig\n",
    "    if dir != 'img':\n",
    "        dir = f'img/{dir}'\n",
    "    else:\n",
    "        pass\n",
    "    if format == 'svg':\n",
    "        dpi=None\n",
    "    # check if dir exists and create it if not\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "    figure.savefig(\n",
    "        f'{dir}/{name}.{format}',\n",
    "        transparent=transparent\n",
    "        bbox_inches='tight',\n",
    "        dpi=dpi, \n",
    "        # format=format,\n",
    "        **kwargs\n",
    "    )\n",
    "    print(f\"Image '{name}.{format}' successfully saved into '{dir}' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a973d2-9229-4daa-8374-48afd8820b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fit(names_list, estimators_list):\n",
    "    counter = 0\n",
    "    names_catched = []\n",
    "    for name, estimator in zip(names_list, estimators_list):\n",
    "        try:\n",
    "            check_is_fitted(estimator)\n",
    "        except BaseException:\n",
    "            pass\n",
    "        else:\n",
    "            names_catched.append(f\"'{name}'\")\n",
    "            counter += 1\n",
    "    if counter > 0:\n",
    "        if counter == len(names_list):\n",
    "            print('All estimators fitted')\n",
    "        else:\n",
    "            print(f'Estimators fitted: {\", \".join(names_catched)}')\n",
    "    else:\n",
    "        print('All estimators not fitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af06b71-ad49-4f4f-93f0-da93a1b415d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_X_y(data, target):\n",
    "    columns = data.columns.tolist()\n",
    "    columns.append(columns.pop(columns.index(target)))\n",
    "    df = data[columns].copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03e9bdb-ff0d-44ca-ab54-d6ff90cd2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(\n",
    "        datasets_list, features_list, target, estimators_list, estimators_names,\n",
    "        datasets_indexes, features_indexes,\n",
    "        sample_frac=1, replace=True, full_results=False, n_folds=1000):\n",
    "    # data size\n",
    "    data_size = len(datasets_list[0])\n",
    "    # sample size\n",
    "    sample_size = np.round(data_size * sample_frac)\n",
    "    # fold range\n",
    "    fold_range = np.arange(0, n_folds)\n",
    "    # results dict\n",
    "    results_dict = {i:np.array([]) for i in estimators_names}\n",
    "    results_full_dict = {i:{} for i in estimators_names}\n",
    "    # for i in fold_range:\n",
    "    for i in estimators_names:\n",
    "        results_full_dict[i] = {f'fold_{fold}':{} for fold in fold_range}\n",
    "    for fold in fold_range:\n",
    "        fold_name = f'fold_{fold}'\n",
    "        sample_idxs = np.random.randint(\n",
    "            low=0, high=data_size, size=sample_size)\n",
    "        zip_ = zip(\n",
    "            estimators_list,\n",
    "            estimators_names,\n",
    "            datasets_indexes,\n",
    "            features_indexes\n",
    "        )\n",
    "        for estimator, name, datasets_idx, features_idx in zip_:\n",
    "            # choose dataset type for estimator\n",
    "            data = datasets_list[datasets_idx]\n",
    "            # data columns\n",
    "            columns = data.columns.tolist()\n",
    "            data = order_X_y(data, target)\n",
    "            data = np.array(data)\n",
    "            # choose features type for estimator\n",
    "            features = features_list[features_idx]\n",
    "            # calculate indexes of estimator features in columns of input X\n",
    "            features_select_idxs = []\n",
    "            for i in features:\n",
    "                features_select_idxs.append(columns.index(i))\n",
    "                \n",
    "            X = data[sample_idxs, :][:, features_select_idxs]\n",
    "            y = data[sample_idxs, :][:, -1]\n",
    "            X = pd.DataFrame(data=X, columns=features)\n",
    "            y_pred = estimator.predict(X)\n",
    "            mrse = mean_squared_error(y, y_pred, squared=False)\n",
    "            results_dict[name] = np.append(results_dict[name], mrse)\n",
    "            \n",
    "            \n",
    "            results_full_dict[name][fold_name]['y_true'] = y\n",
    "            results_full_dict[name][fold_name]['y_pred'] = y_pred\n",
    "            \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314bfb7c-46d0-412d-867e-9b344edb2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_horizontal(\n",
    "        values, labels, labelsize=9, labelweight='medium', labelcolor='0.3',\n",
    "        figsize=(8,3), color='#707070',\n",
    "        width=0.5, s=6,  kind='lol', x_lim_right=None, grid=False):\n",
    "\n",
    "    values = np.array(values)\n",
    "    values = np.flip(values)\n",
    "    yticklabels = np.array(labels)\n",
    "    yticklabels = np.flip(yticklabels)\n",
    "    \n",
    "    yticks = np.arange(0, len(yticklabels), 1)\n",
    "    yticklabels = [str.lower(i) for i in yticklabels]\n",
    "    height = figsize[1]\n",
    "\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    if kind == 'lol':\n",
    "        linewidth = width\n",
    "        ax.scatter(\n",
    "            x=values, y=yticks, linewidth=width, ec='face',\n",
    "            s=s, color=palette[0], clip_on=False\n",
    "        )\n",
    "    elif kind == 'bar':\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Select type of plot: 'lol' or 'bar'\")\n",
    "        \n",
    "    ax.hlines(\n",
    "        xmin=0, xmax=values, y=yticks,\n",
    "        linewidth=width, color=palette[-3], alpha=0.25, clip_on=False)\n",
    "    \n",
    "    ax.xaxis.tick_top()\n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.spines['top'].set_color(color)\n",
    "    ax.spines['top'].set_position(('outward', 15))\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['left'].set_color(color)\n",
    "    ax.spines['left'].set_position(('outward', 15))\n",
    "    ax.set_xlim(left=0, right=x_lim_right)\n",
    "    ax.set_ylim(bottom=0, top=yticks[-1])\n",
    "    ax.set_yticks(ticks=yticks, labels=yticklabels, weight=labelweight, color=color)\n",
    "    plt.grid(grid)\n",
    "    \n",
    "    ax.tick_params(\n",
    "        axis='x', direction='out', size=2, colors=color)\n",
    "    ax.tick_params(\n",
    "        axis='y', direction='out', size=2, left=True,\n",
    "        labelsize=labelsize, labelcolor=labelcolor, colors=color, pad=10)\n",
    "\n",
    "    plt.title('Feature importance')\n",
    "    plt.show()\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1880c2b-7126-45b3-9c07-44804f1bf856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_enet_comparison(data):\n",
    "    \n",
    "    s=7\n",
    "    lw = 1\n",
    "    capsize=1.2\n",
    "    scatter_alpha=0.9\n",
    "    error_alpha=0.9\n",
    "    legend_alpha=0.9\n",
    "\n",
    "    data_histplot = data.melt()\n",
    "    \n",
    "    # figure\n",
    "    f = plt.figure(figsize=(7, 4))\n",
    "    # title\n",
    "    f.suptitle(\n",
    "        'Comparing LR and ENET: simulations on Train Data',\n",
    "        x=0.357, y=1.03, fontsize=10)\n",
    "    # spec\n",
    "    spec = f.add_gridspec(2, 2, height_ratios=[1, 1])\n",
    "    \n",
    "    # histplot\n",
    "    f.add_subplot(spec[1, :])\n",
    "    ax = sns.histplot(\n",
    "        data=data_histplot,\n",
    "        x='value',\n",
    "        hue='variable',\n",
    "        bins=75,\n",
    "        alpha=0.5,\n",
    "        kde=True,\n",
    "        palette=[palette[0], palette[1]])\n",
    "    axis_rstyle(\n",
    "        x_ticks=[0.115, 0.155, 0.005],\n",
    "        y_ticks=[0, 40, 10]\n",
    "    )\n",
    "    # hide legend\n",
    "    ax.get_legend().remove()\n",
    "    # axis labels\n",
    "    plt.xlabel(None)\n",
    "    plt.ylabel(str.capitalize('count'))\n",
    "    plt.tick_params(axis='y', which='major', pad=5)\n",
    "    plt.tick_params(axis='both', labelsize=7)\n",
    "    # title\n",
    "    plt.title('RMSE distribution', fontsize=9)\n",
    "    plt.grid(False)\n",
    "    plt.ylim(0, 45)\n",
    "    \n",
    "    # CI plot\n",
    "    f.add_subplot(spec[0, 0])\n",
    "    plot_interval_confidence(\n",
    "        data=data,\n",
    "        scatter_kws={\n",
    "            's': s,\n",
    "            'alpha': scatter_alpha\n",
    "        },\n",
    "        error_kws={\n",
    "            'lw': lw,\n",
    "            'capsize': capsize,\n",
    "            'alpha': error_alpha}\n",
    "    )\n",
    "    axis_rstyle()\n",
    "    # xaxis customization\n",
    "    plt.gca().spines['bottom'].set_visible(False)\n",
    "    plt.tick_params(bottom=False, labelbottom=False)\n",
    "    plt.tick_params(axis='y', labelsize=7)\n",
    "    # yaxis customization\n",
    "    yticks = arange(0.134, 0.136, 0.001, True)\n",
    "    plt.yticks(yticks)\n",
    "    plt.ylim(0.134, 0.136)\n",
    "    plt.ylabel('RMSE')\n",
    "    # title\n",
    "    plt.title('Confidence intervals (95%)', fontsize=9)\n",
    "    plt.grid(False)\n",
    "    \n",
    "    \n",
    "    # PI plot\n",
    "    f.add_subplot(spec[0, 1])\n",
    "    plot_interval_prediction(\n",
    "        data=data,\n",
    "        kind='std',\n",
    "        scatter_kws={\n",
    "            's': s,\n",
    "            'alpha': scatter_alpha\n",
    "        },\n",
    "        error_kws={\n",
    "            'lw': lw,\n",
    "            'capsize': capsize,\n",
    "            'alpha': error_alpha}\n",
    "    )\n",
    "    axis_rstyle(\n",
    "        y_ticks=[0.125, 0.15, 0.010]\n",
    "    )\n",
    "    # xaxis customization\n",
    "    plt.gca().spines['bottom'].set_visible(False)\n",
    "    plt.tick_params(bottom=False, labelbottom=False)\n",
    "    plt.tick_params(axis='y', labelsize=7)\n",
    "    # yaxis\n",
    "    plt.ylim(0.125, 0.145)\n",
    "    plt.ylabel(None)\n",
    "    # title\n",
    "    plt.title('Prediction intervals', fontsize=9)\n",
    "    plt.grid(False)\n",
    "    # create legend\n",
    "    patch_lr = Line2D(\n",
    "        [], [], label='Linear Regression', marker='o',\n",
    "        markersize=3, color=palette[0], linestyle='None', alpha=legend_alpha)\n",
    "    patch_enet = Line2D(\n",
    "        [], [], label='Elastic Net', marker='o',\n",
    "        markersize=3, color=palette[1], linestyle='None', alpha=legend_alpha)\n",
    "    plt.legend(\n",
    "        handles=[patch_lr, patch_enet], fontsize=8,\n",
    "        markerscale=1, frameon=False, alignment='left', handletextpad=-0.15,\n",
    "        loc='upper left', bbox_to_anchor=(1,1)\n",
    "    )\n",
    "    # subplot adjust\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed6983-93cf-4ed9-b447-ed798a5533e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interval_prediction(data, ax=None, palette=None, kind='pi', scatter_kws={}, error_kws={}):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    if palette is None:\n",
    "        palette = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    if kind == 'std':\n",
    "        z = 1\n",
    "    if kind == 'pi':\n",
    "        z = 1.96\n",
    "\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "\n",
    "    xticks = np.arange(0, len(data.columns), 1)\n",
    "    xtickslabels = data.columns\n",
    "\n",
    "    size = len(mean.index)\n",
    "    \n",
    "    for i, j in zip(mean.index, np.arange(0, size)):\n",
    "        pi_plot = ax.scatter(\n",
    "            x=i,\n",
    "            y=mean[i],\n",
    "            color=palette[j],\n",
    "            **scatter_kws\n",
    "        )\n",
    "        pi_plot = ax.errorbar(\n",
    "            x=i,\n",
    "            y=mean[i],\n",
    "            yerr=z*std[i],\n",
    "            linestyle='none',\n",
    "            color=palette[j],\n",
    "            **error_kws\n",
    "        )\n",
    "    ax.set_xlim(-0.5, xticks[-1]+0.5)\n",
    "    \n",
    "    return pi_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c049ed2-20ea-4e9f-9e74-9844d36d0ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interval_confidence(data, ax=None, scatter_kws={}, error_kws={}):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    xticks = np.arange(0, len(data.columns), 1)\n",
    "    xtickslabels = data.columns\n",
    "\n",
    "    for i, j in zip(data.columns, np.arange(0, len(data.columns))):\n",
    "        \n",
    "        bootstrap = ci_bootstrap(data[i])\n",
    "        mean = bootstrap['statistic']\n",
    "        margin = bootstrap['proxi_margin']\n",
    "        \n",
    "        ci_plot = ax.scatter(\n",
    "            x=i,\n",
    "            y=mean,\n",
    "            color=palette[j],\n",
    "            **scatter_kws\n",
    "        )\n",
    "        ci_plot = ax.errorbar(\n",
    "            x=i,\n",
    "            y=mean,\n",
    "            yerr=margin,\n",
    "            linestyle='none',\n",
    "            color=palette[j],\n",
    "            **error_kws\n",
    "        )\n",
    "    ax.set_xlim(-0.5, xticks[-1]+0.5)\n",
    "\n",
    "    return ci_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229f675-cf81-4f9b-b776-3a45f33c75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_estimators_comparing(\n",
    "        data,\n",
    "        labels,\n",
    "        ylabels=None,\n",
    "        kind='bar',\n",
    "        figsize=(8, 4),\n",
    "        width=0.2,\n",
    "        markersize=4,\n",
    "        linewidth=0.5,\n",
    "        palette=None,\n",
    "        title_plot=None,\n",
    "        ax0_y_ticks=None,\n",
    "        ax1_y_ticks=None,\n",
    "        x_ticks_fontsize=8,\n",
    "        x_ticks_weight='bold',\n",
    "        x_labels_color='#7F7F7F',\n",
    "        capitalize=True,\n",
    "        spines_width=0.75,\n",
    "        spines_color=custom_axis_color,\n",
    "        ticks_step=None,\n",
    "        ticks_color=custom_axis_color,\n",
    "        ticklabels_color=custom_axis_color,\n",
    "        grid=True):\n",
    "\n",
    "    df = data.copy()\n",
    "    xticks = np.arange(0, len(df), 1)\n",
    "\n",
    "    if capitalize:\n",
    "        df.columns = [i.capitalize() for i in df.columns]\n",
    "    \n",
    "    if palette is None:\n",
    "        color_palette = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "        color0 = color_palette[0]\n",
    "        color1 = color_palette[1]\n",
    "    else:\n",
    "        color0 = palette[0]\n",
    "        color1 = palette[1]\n",
    "    \n",
    "    f, ax = plt.subplots(2,1, sharex=False, figsize=figsize)\n",
    "    \n",
    "    # AX0\n",
    "    # plots\n",
    "    for col, color in zip(df.columns, palette):\n",
    "        ax[0].scatter(\n",
    "            x=xticks, y=df[col], label=col, s=markersize, color=color)\n",
    "        ax[0].plot(\n",
    "            xticks, df[col], lw=linewidth, color=color)\n",
    "        ax[0].hlines(\n",
    "            df[col].mean(), xticks[0], xticks[-1], lw=0.75, color=color)\n",
    "    # spines\n",
    "    ax[0].spines['bottom'].set_visible(False)\n",
    "    ax[0].spines['bottom'].set_linewidth(0.5)\n",
    "    ax[0].spines['bottom'].set_alpha(0.5)\n",
    "    ax[0].spines['bottom'].set_linewidth(spines_width)\n",
    "    ax[0].spines['left'].set_position(('outward', 5))\n",
    "    ax[0].spines['left'].set_color(spines_color)\n",
    "    ax[0].spines['left'].set_linewidth(spines_width)\n",
    "    # xticks\n",
    "    ax[0].set_xticks(\n",
    "        ticks=xticks, labels=xticks, weight=x_ticks_weight,\n",
    "        fontsize=x_ticks_fontsize)\n",
    "    ax[0].tick_params(\n",
    "        bottom=False, pad=9, labelcolor=x_labels_color)\n",
    "    # yticks\n",
    "    if ax0_y_ticks is not None:\n",
    "        ax0_y_ticks_ = np.arange(\n",
    "            ax0_y_ticks[0],\n",
    "            ax0_y_ticks[1] + ax0_y_ticks[2],\n",
    "            ax0_y_ticks[2])\n",
    "        ax[0].set_yticks(ticks=ax0_y_ticks_)\n",
    "        # ylim\n",
    "        ax[0].set_ylim(ax0_y_ticks_[0], ax0_y_ticks_[-1])\n",
    "    ax[0].tick_params(\n",
    "        axis='y', left=True, direction='out',\n",
    "        color=ticks_color, labelcolor=ticklabels_color, pad=5)\n",
    "    # xlim\n",
    "    ax[0].set_xlim(xticks[0]-0.5, xticks[-1]+0.5)\n",
    "    # ylabel\n",
    "    if ylabels is not None:\n",
    "        ax[0].set_ylabel(ylabels[0])\n",
    "    if grid:\n",
    "        # grid (only horizotal and not at the end of axis)\n",
    "        ax[0].grid(visible=False, axis='y')\n",
    "        ax0_y_ticks_final = ax[0].get_yticks()\n",
    "        for i in ax0_y_ticks_final[1:-1]:\n",
    "            ax[0].axhline(i, lw=0.5, ls=':', color='0.85')\n",
    "    else:\n",
    "        ax[0].grid(False)\n",
    "    # title\n",
    "    if title_plot is not None:\n",
    "        ax[0].set_title(title_plot)\n",
    "    \n",
    "    # AX1\n",
    "    # calculate delta\n",
    "    df_columns = list(df.columns)\n",
    "    delta = df[df_columns[1]] - df[df_columns[0]]\n",
    "    # define colors\n",
    "    # if delta<0, i==0, color0 / if delta>0, i==1, color1\n",
    "    colors_marks = np.where(delta < 0, 0, 1)\n",
    "    colors = [color0 if i==0 else color1 for i in colors_marks]\n",
    "    # count 0 and 1 in marks\n",
    "    marks_unique, marks_counts = np.unique(colors_marks, return_counts=True)\n",
    "    marks_dict = dict(zip(marks_unique, marks_counts))\n",
    "    # plots\n",
    "    if kind == 'bar':\n",
    "        ax[1].bar(\n",
    "            x=xticks, height=delta, width=width,\n",
    "            ec='none', color=colors, zorder=10)\n",
    "        # line 0\n",
    "        ax[1].hlines(0, xticks[0], xticks[-1], lw=0.5, color='0.90', zorder=1)\n",
    "    if kind == 'lol':\n",
    "        ax[1].scatter(\n",
    "            x=xticks, y=delta, s=markersize, ec='face',\n",
    "            color=colors, zorder=10)\n",
    "        for i, j in zip(xticks, delta):\n",
    "            color = palette[0] if j<0 else palette[1]\n",
    "            ax[1].plot(\n",
    "                [i, i], [0, j], lw=0.5, alpha=0.35,\n",
    "                color=color, clip_on=False, zorder=1)\n",
    "        # line 0\n",
    "        ax[1].hlines(0, xticks[0], xticks[-1], lw=1, color='0.90', zorder=10)\n",
    "    if kind == 'line':\n",
    "        for i, j in zip(xticks, delta):\n",
    "            color = palette[0] if j<0 else palette[1]\n",
    "            ax[1].plot(\n",
    "                [i, i], [0, j], lw=1.5,\n",
    "                color=color, clip_on=False, zorder=10)\n",
    "        # line 0\n",
    "        ax[1].hlines(0, xticks[0], xticks[-1], lw=1, color='0.90', zorder=1)\n",
    "    # spines\n",
    "    ax[1].spines['bottom'].set_visible(False)\n",
    "    ax[1].spines['bottom'].set_linewidth(0.5)\n",
    "    ax[1].spines['bottom'].set_alpha(0.5)\n",
    "    ax[1].spines['bottom'].set_linewidth(spines_width)\n",
    "    ax[1].spines['left'].set_position(('outward', 5))\n",
    "    ax[1].spines['left'].set_color(spines_color)\n",
    "    ax[1].spines['left'].set_linewidth(spines_width)\n",
    "    # xticks\n",
    "    ax[1].set_xticks(ticks=xticks)\n",
    "    ax[1].tick_params(\n",
    "        axis='x', bottom=False, labelbottom=False, labelcolor=ticklabels_color)\n",
    "    # yticks\n",
    "    if ax1_y_ticks is not None:\n",
    "        ax1_y_ticks_ = np.arange(\n",
    "            ax1_y_ticks[0],\n",
    "            ax1_y_ticks[1] + ax1_y_ticks[2],\n",
    "            ax1_y_ticks[2])\n",
    "        ax[1].set_yticks(ticks=ax1_y_ticks_)\n",
    "        # ylim\n",
    "        ax[1].set_ylim(ax1_y_ticks_[0], ax1_y_ticks_[-1])\n",
    "    ax[1].tick_params(\n",
    "        axis='y', left=True, direction='out',\n",
    "        color=ticks_color, labelcolor=ticklabels_color, pad=5)\n",
    "    # xlim\n",
    "    ax[1].set_xlim(xticks[0]-0.5, xticks[-1]+0.5)\n",
    "    # ylabel\n",
    "    if ylabels is not None:\n",
    "        ax[1].set_ylabel(ylabels[1])\n",
    "    if grid:\n",
    "        # grid (only horizotal and not at the end of axis)\n",
    "        ax[1].grid(visible=False, axis='y')\n",
    "        ax1_y_ticks_final = ax[1].get_yticks()\n",
    "        for i in ax1_y_ticks_final[1:-1]:\n",
    "            ax[1].axhline(i, lw=0.5, ls=':', color='0.85')\n",
    "    else:\n",
    "        ax[1].grid(False)\n",
    "    \n",
    "    # legend\n",
    "    # create handles\n",
    "    handle00 = Line2D(\n",
    "        [], [], label=labels[0], marker='o',\n",
    "        markersize=3, color=palette[0],\n",
    "        linestyle='None')\n",
    "    handle01 = Line2D(\n",
    "        [], [], label=labels[1], marker='o',\n",
    "        markersize=3, color=palette[1],\n",
    "        linestyle='None')\n",
    "    handle10 = Line2D(\n",
    "        [], [], label=marks_dict[0], marker='s',\n",
    "        markersize=3, color=color0,\n",
    "        linestyle='None')\n",
    "    handle11 = Line2D(\n",
    "        [], [], label=marks_dict[1], marker='s',\n",
    "        markersize=3, color=color1,\n",
    "        linestyle='None')\n",
    "    handles00 = [handle00, handle01]\n",
    "    handles10 = [handle10, handle11]\n",
    "    # create legend\n",
    "    ax0_legend = ax[0].legend(\n",
    "        handles=handles00, fontsize=8, alignment='left', markerscale=1,\n",
    "        handletextpad=0.75, handlelength=0.75, frameon=False,\n",
    "        bbox_to_anchor=(1+figsize[0]*0.0015, 1), loc='upper left', labelcolor='0.3')\n",
    "    ax1_legend = ax[1].legend(\n",
    "        handles=handles10, fontsize=8, alignment='left', markerscale=1,\n",
    "        handletextpad=0.75, handlelength=0.75, frameon=False,\n",
    "        bbox_to_anchor=(1+figsize[0]*0.0015, 1), loc='upper left', labelcolor='0.3')\n",
    "\n",
    "    # set ticks step\n",
    "    if ticks_step is not None:\n",
    "        loc = matplotlib.ticker.MultipleLocator(base=ticks_step) # this locator puts ticks at regular intervals\n",
    "        ax[0].xaxis.set_major_locator(loc)\n",
    "        ax[1].xaxis.set_major_locator(loc)\n",
    "    \n",
    "    # subplots adjust\n",
    "    plt.subplots_adjust(hspace=0.25)\n",
    "    plt.show()\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f93a42a-c967-4e36-975b-66792bb9b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_interval(model, X_train, y_train, x0, alpha: float = 0.05):\n",
    "  ''' Compute a prediction interval around the model's prediction of x0\n",
    "  with Bootstrap 632 rule.\n",
    "\n",
    "  INPUT\n",
    "    model\n",
    "      A predictive model with `fit` and `predict` methods\n",
    "    X_train: numpy array of shape (n_samples, n_features)\n",
    "      A numpy array containing the training input data\n",
    "    y_train: numpy array of shape (n_samples,)\n",
    "      A numpy array containing the training target data\n",
    "    x0\n",
    "      A new data point, of shape (n_features,)\n",
    "    alpha: float = 0.05\n",
    "      The prediction uncertainty\n",
    "\n",
    "  OUTPUT\n",
    "    A triple (`lower`, `pred`, `upper`) with `pred` being the prediction\n",
    "    of the model and `lower` and `upper` constituting the lower- and upper\n",
    "    bounds for the prediction interval around `pred`, respectively. '''\n",
    "\n",
    "  # Number of training samples\n",
    "  n = X_train.shape[0]\n",
    "\n",
    "  # The authors choose the number of bootstrap samples as the square root\n",
    "  # of the number of samples\n",
    "  nbootstraps = np.sqrt(n).astype(int)\n",
    "\n",
    "  # Compute the m_i's and the validation residuals\n",
    "  bootstrap_preds, val_residuals = np.empty(nbootstraps), []\n",
    "  for b in range(nbootstraps):\n",
    "    train_idxs = np.random.choice(range(n), size = n, replace = True)\n",
    "    val_idxs = np.array([idx for idx in range(n) if idx not in train_idxs])\n",
    "    model.fit(X_train[train_idxs, :], y_train[train_idxs])\n",
    "    preds = model.predict(X_train[val_idxs])\n",
    "    val_residuals.append(y_train[val_idxs] - preds)\n",
    "    bootstrap_preds[b] = model.predict(x0)\n",
    "  bootstrap_preds -= np.mean(bootstrap_preds)\n",
    "  val_residuals = np.concatenate(val_residuals)\n",
    "\n",
    "  # Compute the prediction and the training residuals\n",
    "  model.fit(X_train, y_train)\n",
    "  preds = model.predict(X_train)\n",
    "  train_residuals = y_train - preds\n",
    "\n",
    "  # Take percentiles of the training- and validation residuals to enable\n",
    "  # comparisons between them\n",
    "  val_residuals = np.percentile(val_residuals, q = np.arange(100))\n",
    "  train_residuals = np.percentile(train_residuals, q = np.arange(100))\n",
    "\n",
    "  # Compute the .632+ bootstrap estimate for the sample noise and bias\n",
    "  no_information_error = np.mean(np.abs(np.random.permutation(y_train) - \\\n",
    "    np.random.permutation(preds)))\n",
    "  generalisation = np.abs(val_residuals.mean() - train_residuals.mean())\n",
    "  no_information_val = np.abs(no_information_error - train_residuals)\n",
    "  relative_overfitting_rate = np.mean(generalisation / no_information_val)\n",
    "  weight = 0.632 / (1 - 0.368 * relative_overfitting_rate)\n",
    "  residuals = (1 - weight) * train_residuals + weight * val_residuals\n",
    "\n",
    "  # Construct the C set and get the percentiles\n",
    "  C = np.array([m + o for m in bootstrap_preds for o in residuals])\n",
    "  qs = [100 * alpha / 2, 100 * (1 - alpha / 2)]\n",
    "  percentiles = np.percentile(C, q = qs)\n",
    "\n",
    "  return percentiles[0], model.predict(x0), percentiles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca14e19-3bdf-4e09-8cff-c57fdbef112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(\n",
    "        estimator, data, features, target, pipeline_transform, n_folds=10):\n",
    "    \n",
    "    k_fold = KFold(n_splits=n_folds, random_state=None, shuffle=False)\n",
    "    k_fold_splitted = k_fold.split(data)\n",
    "    \n",
    "    fit_time = np.empty(n_folds)\n",
    "    test_score = np.empty(n_folds)\n",
    "\n",
    "    encoder = OrdinalEncoder(\n",
    "        encoding_method='ordered',\n",
    "        variables=categorical_transform,\n",
    "        missing_values='ignore',\n",
    "        unseen='encode'\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(k_fold_splitted):\n",
    "        data_train = train_cv.iloc[train_index, :]\n",
    "        data_test = train_cv.iloc[test_index, :]\n",
    "    \n",
    "        X_train = data_train[features].copy()\n",
    "        y_train = data_train[target].copy()\n",
    "        X_test = data_test[features].copy()\n",
    "        y_test = data_test[target].copy()\n",
    "    \n",
    "        X_train[features] = pipeline_transform.fit_transform(X_train, y_train)\n",
    "        X_test[features] = pipeline_transform.transform(X_test)\n",
    "        \n",
    "        st = stopwatch.start()\n",
    "        estimator.fit(X_train, y_train)\n",
    "        fit_time[i] = stopwatch.stop_sec(st)\n",
    "        y_pred = estimator.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        test_score[i] = rmse\n",
    "\n",
    "        results_dict = {\n",
    "            'test_score': test_score,\n",
    "            'fit_time': fit_time\n",
    "        }\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815645b2-288f-4a79-9c3f-7c5ca05af29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_session(name, directory='sessions'):\n",
    "    if directory != 'sessions':\n",
    "        directory = f'sessions/{directory}/'\n",
    "    else:\n",
    "        directory = 'sessions/'\n",
    "    # check if dir exists and create it if not\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "    # save session\n",
    "    dill.dump_session(directory+name)\n",
    "\n",
    "\n",
    "def load_session(name, directory='sessions'):\n",
    "    if directory != 'sessions':\n",
    "        directory = f'sessions/{dir}/'\n",
    "    else:\n",
    "        directory = 'sessions/'\n",
    "    # load session\n",
    "    dill.load_session(directory+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d122e-c9bd-47d0-9415-61562dd006df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_predicted(data_pred_actual, variable, points_num=20):\n",
    "\n",
    "    df = data_pred_actual[:points_num].copy()\n",
    "    \n",
    "    if variable == 'index':\n",
    "        df = df.sort_index()\n",
    "        plt.scatter(\n",
    "            df.index, df['actual'],\n",
    "            s=10, ec='none', color=palette[0], zorder=10, label='Actual')\n",
    "        plt.plot(\n",
    "            df.index, df['actual'],\n",
    "            color=alpha_color(palette[0], 0.15), zorder=1)\n",
    "        \n",
    "        plt.scatter(\n",
    "            df.index, df['predicted'],\n",
    "            s=10, ec='none', color=palette[1], zorder=10, label='Predicted')\n",
    "        plt.plot(\n",
    "            df.index, df['predicted'],\n",
    "            color=alpha_color(palette[1], 0.15), zorder=1)\n",
    "    \n",
    "    else:\n",
    "        df = df.sort_values(variable)\n",
    "        xticks = df[variable].tolist()\n",
    "        delta = (xticks[-1] - xticks[0]) / 100\n",
    "        \n",
    "        plt.scatter(\n",
    "            df[variable]-delta, df['actual'],\n",
    "            s=10, ec='none', color=palette[0], zorder=10, label='Actual')\n",
    "        # plt.plot(\n",
    "        #     df[variable]-delta, df['actual'],\n",
    "        #     lw=0.25, color=alpha_color(palette[0], 0.5))\n",
    "        \n",
    "        plt.scatter(\n",
    "            df[variable]+delta, df['predicted'],\n",
    "            s=10, ec='none', color=palette[1], zorder=10, label='Predicted')\n",
    "        # plt.plot(\n",
    "        #     df[variable]+delta, df['predicted'],\n",
    "        #     lw=0.25, color=alpha_color(palette[1], 0.5))\n",
    "\n",
    "        for index in df.index:\n",
    "            plt.plot(\n",
    "                [df[variable]-delta, df[variable]+delta], [df['actual'], df['predicted']],\n",
    "                color=alpha_color(palette[0], 0.25), zorder=1\n",
    "            )\n",
    "\n",
    "    plt.title(variable, **title_inline)\n",
    "    plt.legend(**legend_inline, ncols=2)\n",
    "    plt.grid(False)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646627ef-e7bb-41d2-9562-ec5e3da489dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_predicted_single_var(data, variable):\n",
    "\n",
    "    df = data.copy()\n",
    "    df = df.sort_values(variable)\n",
    "    xticks = df[variable].tolist()\n",
    "    delta = (xticks[-1] - xticks[0]) / 100\n",
    "    \n",
    "    plt.scatter(\n",
    "        df[variable]-delta, df['actual'],\n",
    "        s=10, ec='none', color=palette[0], zorder=10, label='Actual')\n",
    "    \n",
    "    plt.scatter(\n",
    "        df[variable]+delta, df['predicted'],\n",
    "        s=10, ec='none', color=palette[1], zorder=10, label='Predicted')\n",
    "\n",
    "    for index in df.index:\n",
    "        plt.plot(\n",
    "            [df[variable]-delta, df[variable]+delta], [df['actual'], df['predicted']],\n",
    "            lw=0.5, color=alpha_color(palette[0], 0.15), zorder=1\n",
    "        )\n",
    "\n",
    "    plt.legend(**legend_inline, ncols=2)\n",
    "    plt.grid(False)\n",
    "    plt.xticks(ticks=list(set(data_pred_actual[variable])), labels=list(set(data_pred_actual[variable])))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33402e2a-04a5-4ced-9db7-e203796a146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_round(x, scale=1, error='skip'):\n",
    "    \n",
    "    '''\n",
    "    Round x if possible\n",
    "    '''\n",
    "    try:\n",
    "        return round(x, ndigits=scale)\n",
    "    except TypeError:\n",
    "        if error == 'type':\n",
    "            print(f'TypeError: {x}')\n",
    "        elif error == 'skip':\n",
    "            pass\n",
    "        else:\n",
    "            print(\"'error' must be 'type' or 'skip'\")\n",
    "            return\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c27a3f-bcba-4205-9948-edf4558345d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness(df):\n",
    "\n",
    "    df = pd.DataFrame(df.skew(numeric_only=True),\n",
    "                      columns=['Skewness'],\n",
    "                      index=None)\n",
    "\n",
    "    df['Highly skewed'] = (abs(df['Skewness']) > 0.5)\n",
    "    df['abs'] = abs(df['Skewness'])\n",
    "\n",
    "    df = df.sort_values(by=['abs', 'Highly skewed'], ascending=False)\n",
    "    df = df.drop('abs', axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b755ecb9-ff91-4e78-baf0-5b0fba95ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kurtosis(df):\n",
    "\n",
    "    df = pd.DataFrame(df.kurtosis(numeric_only=True),\n",
    "                      columns=['Kurtosis'],\n",
    "                      index=None)\n",
    "    df['Type'] = np.nan\n",
    "\n",
    "    df.loc[df['Kurtosis'] > 1, 'Type'] = 'Too Peaked'\n",
    "    df.loc[df['Kurtosis'] < -1, 'Type'] = 'Too Flat'\n",
    "    df.loc[(df['Kurtosis'] <= 1) & (df['Kurtosis'] >= -1), 'Type'] = 'Normal'\n",
    "    \n",
    "    df['abs'] = abs(df['Kurtosis'])\n",
    "    df = df.sort_values(by=['abs', 'Type'], ascending=False)\n",
    "    df = df.drop('abs', axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860c34c-539e-4ab0-ba2a-8b8908e28ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_add_after_every(lst, element, add_every):\n",
    "    # using [item for subgroup in groups for item in subgroup]\n",
    "    lst_new = [\n",
    "        x for y in (lst[i:i+add_every] + [element] * (i < len(lst) - add_every + 1) \n",
    "                    for i in range(0, len(lst), add_every)) for x in y\n",
    "    ]\n",
    "    return lst_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14ef42-bca4-444d-8e47-937ecebb90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_add_xaxis(\n",
    "            ticks,\n",
    "            labels,\n",
    "            width=0.5,\n",
    "            offset=0,\n",
    "            offset_first_axis=5,\n",
    "            color_labels=None,\n",
    "            color_ticks=None,\n",
    "            ax=None):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if ax is None: ax = plt.gca()\n",
    "\n",
    "    ax_xticks = ax.get_xticks()\n",
    "    ax_xticks_length = len(ax_xticks)\n",
    "    ax_xticks_min, ax_xticks_max = ax_xticks[0], ax_xticks[-1]\n",
    "    ax_xticks_lim = ax.get_xlim()\n",
    "\n",
    "    for n, l, idx in zip(ticks, labels, arange(len(ticks))):\n",
    "        \n",
    "        if n < ax_xticks_length:\n",
    "            n_corrected = (2*n-1) + 2\n",
    "            l = list_add_after_every(l, ' ', 1)\n",
    "            l = [''] + l\n",
    "        else:\n",
    "            n_corrected = n\n",
    "\n",
    "        t = np.linspace(ax_xticks_min, ax_xticks_max, n_corrected)\n",
    "\n",
    "        # axes for labels\n",
    "        ax_labels = ax.twiny()\n",
    "        ax_labels.grid(False)\n",
    "        ax_labels.set_xticks(ticks=t, labels=l)\n",
    "        \n",
    "        if idx == 0:\n",
    "            ax_labels.set_xlim(ax_xticks_lim)\n",
    "\n",
    "        ax_labels.spines[['top', 'left', 'bottom', 'right']].set_visible(False)\n",
    "        ax_labels.spines['bottom'].set_position(('outward', offset))\n",
    "        \n",
    "        ax_labels.tick_params(\n",
    "            axis='x', direction='out',\n",
    "            top=False, left=False, right=False, bottom=False,\n",
    "            labeltop=False, labelbottom=True, labelleft=False, labelright=False)\n",
    "        if color_labels:\n",
    "            ax_labels.tick_params(axis='x', labelcolor=color_labels)\n",
    "\n",
    "        # axes for ticks\n",
    "        ax_ticks = ax.twiny()\n",
    "        ax_ticks.grid(False)\n",
    "        ax_ticks.set_xticks(t)\n",
    "\n",
    "        if color_ticks:\n",
    "            ax_ticks.tick_params(axis='x', color=color_ticks)\n",
    "        \n",
    "        if idx == 0:\n",
    "            pad = offset_first_axis=5,\n",
    "            ax_ticks.set_xlim(ax_xticks_lim)\n",
    "            size = 3\n",
    "        else:\n",
    "            pad = offset + 5\n",
    "            size = 10\n",
    "            \n",
    "        ax_ticks.tick_params(\n",
    "            axis='x', direction='out', width=width, size=size,\n",
    "            bottom=True, labelbottom=False, top=False, labeltop=False)\n",
    "\n",
    "        ax_ticks.spines[['top', 'left', 'bottom', 'right']].set_visible(False)\n",
    "        ax_ticks.spines['bottom'].set_position(('outward', pad))\n",
    "\n",
    "        if idx != 0:\n",
    "            # hide every second tick (not count first and last)\n",
    "            for i in ax_ticks.xaxis.get_major_ticks()[1:-1][::2]:\n",
    "                i.set_visible(False)\n",
    "            ax_ticks.xaxis.get_major_ticks()[0].set_visible(False)\n",
    "            ax_ticks.xaxis.get_major_ticks()[-1].set_visible(False)\n",
    "        \n",
    "        offset += 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5125ece4-29be-47dd-a319-d1ed3c254d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_column_after(data, column_to_move, column_insert_after):\n",
    "\n",
    "    '''\n",
    "    Moves 'column_to_move' from its position to the position after 'column_insert_after'\n",
    "\n",
    "    Before:\n",
    "     col1 | column_insert_after | col2 | col3 | col4 | column_to_move | col5\n",
    "    -------------------------------------------------------------------------\n",
    "    \n",
    "    After:\n",
    "     col1 | column_insert_after | column_to_move | col2 | col3 | col4 | col5\n",
    "    -------------------------------------------------------------------------\n",
    "    '''\n",
    "\n",
    "    df = data.copy()\n",
    "    \n",
    "    col = df.pop(column_to_move)\n",
    "    idx = df.columns.get_loc(column_insert_after) + 1\n",
    "    df.insert(idx, column_to_move, col)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe610d-f7b3-4eb8-985a-d09003c0ab5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
